<!DOCTYPE html>

<html lang="en" data-content_root="../../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>scistanpy.model.components.transformations.transformed_parameters &#8212; SciStanPy Alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/alabaster.css?v=27fed22d" />
    <script src="../../../../../_static/documentation_options.js?v=6b921976"></script>
    <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for scistanpy.model.components.transformations.transformed_parameters</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Parameter transformation components for SciStanPy models.</span>

<span class="sd">This module provides a comprehensive library of mathematical transformations that</span>
<span class="sd">can be applied to model parameters. These transformations enable complex model</span>
<span class="sd">construction through composition of simple mathematical operations while maintaining</span>
<span class="sd">automatic differentiation capabilities and Stan code generation.</span>

<span class="sd">The transformation system supports:</span>

<span class="sd">Transformation Categories:</span>
<span class="sd">    - **Arithmetic Operations**: Addition, subtraction, multiplication, division, powers</span>
<span class="sd">    - **Mathematical Functions**: Logarithms, exponentials, absolute values, sigmoids</span>
<span class="sd">    - **Statistical Operations**: Normalization, log-sum-exp, reductions</span>
<span class="sd">    - **Growth Models**: Exponential and sigmoid growth parameterizations</span>
<span class="sd">    - **Array Operations**: Indexing, slicing, convolution</span>

<span class="sd">Key Features:</span>
<span class="sd">    - **Multi-Backend Support**: Works with NumPy, PyTorch, and Stan</span>
<span class="sd">    - **Automatic Differentiation**: Maintains gradient flow for PyTorch optimization</span>
<span class="sd">    - **Stan Code Generation**: Automatic translation to Stan programming language</span>
<span class="sd">    - **Operator Overloading**: Natural mathematical syntax through Python operators</span>
<span class="sd">    - **Shape Broadcasting**: Automatic handling of multi-dimensional operations</span>
<span class="sd">    - **Type Safety**: Comprehensive validation and error checking</span>

<span class="sd">Transformation Architecture:</span>
<span class="sd">    The module provides several base classes that establish the transformation framework:</span>
<span class="sd">    - **TransformableParameter**: Mixin enabling operator overloading</span>
<span class="sd">    - **Transformation**: Base class for all transformation types</span>
<span class="sd">    - **TransformedParameter**: Foundation for parameter transformations</span>
<span class="sd">    - **BinaryTransformedParameter**: Two-operand mathematical operations</span>
<span class="sd">    - **UnaryTransformedParameter**: Single-operand mathematical operations</span>

<span class="sd">Advanced Transformations:</span>
<span class="sd">    Beyond basic arithmetic, the module includes specialized transformations for:</span>
<span class="sd">    - Growth modeling (exponential, sigmoid) with multiple parameterizations</span>
<span class="sd">    - Sequence processing (convolution operations)</span>
<span class="sd">    - Array manipulation (indexing with NumPy-compatible syntax)</span>
<span class="sd">    - Numerical stability (log-space operations, stable sigmoid)</span>
<span class="sd">    - Statistical operations (normalization, reductions)</span>

<span class="sd">Note that these will not typically be instantiated directly. Instead, use Python&#39;s</span>
<span class="sd">inbuilt operators between other model components or else use SciStanPy&#39;s `operations`</span>
<span class="sd">submodule.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">overload</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">npt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">scistanpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">utils</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scistanpy.model.components</span><span class="w"> </span><span class="kn">import</span> <span class="n">abstract_model_component</span><span class="p">,</span> <span class="n">constants</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scistanpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">custom_types</span>

<span class="c1"># pylint: disable=too-many-lines</span>


<div class="viewcode-block" id="TransformableParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.TransformableParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformableParameter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class enabling mathematical operator overloading for parameters.</span>

<span class="sd">    This mixin class provides Python operator overloading capabilities that allow</span>
<span class="sd">    parameters to be combined using natural mathematical syntax. Each operator</span>
<span class="sd">    creates an appropriate TransformedParameter instance that represents the</span>
<span class="sd">    mathematical operation.</span>

<span class="sd">    The mixin supports all standard arithmetic operators:</span>
<span class="sd">    - Addition (+), subtraction (-)</span>
<span class="sd">    - Multiplication (*), division (/)</span>
<span class="sd">    - Exponentiation (**)</span>
<span class="sd">    - Unary negation (-)</span>

<span class="sd">    Each operation supports both left and right operand positioning, enabling</span>
<span class="sd">    flexible mathematical expressions with mixed parameter and constant types.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; param1 = Normal(mu=0, sigma=1)</span>
<span class="sd">        &gt;&gt;&gt; param2 = Normal(mu=1, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; # All of these create TransformedParameter instances</span>
<span class="sd">        &gt;&gt;&gt; sum_param = param1 + param2</span>
<span class="sd">        &gt;&gt;&gt; scaled_param = 2 * param1</span>
<span class="sd">        &gt;&gt;&gt; ratio_param = param1 / param2</span>
<span class="sd">        &gt;&gt;&gt; power_param = param1 ** 2</span>
<span class="sd">        &gt;&gt;&gt; negated_param = -param1</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">AddParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__radd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">AddParameter</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SubtractParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__rsub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SubtractParameter</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MultiplyParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__rmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MultiplyParameter</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DivideParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__rtruediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DivideParameter</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__pow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">PowerParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__rpow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">PowerParameter</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__neg__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">NegateParameter</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>



<div class="viewcode-block" id="Transformation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Transformation">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Transformation</span><span class="p">(</span><span class="n">abstract_model_component</span><span class="o">.</span><span class="n">AbstractModelComponent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for all parameter transformations in SciStanPy.</span>

<span class="sd">    This abstract base class provides the foundational infrastructure for</span>
<span class="sd">    creating transformations that can be used in both the transformed parameters</span>
<span class="sd">    and transformed data blocks of Stan models. It handles the common aspects</span>
<span class="sd">    of transformation operations including shape validation and Stan code generation.</span>

<span class="sd">    :cvar SHAPE_CHECK: Whether to perform automatic shape checking. Defaults to True.</span>

<span class="sd">    Key Responsibilities:</span>
<span class="sd">    - Coordinate transformation assignment code generation</span>
<span class="sd">    - Manage shape validation for transformation outputs</span>
<span class="sd">    - Provide abstract interface for Stan operation writing</span>
<span class="sd">    - Handle index options and assignment formatting</span>

<span class="sd">    The class provides methods for generating Stan code assignments and manages</span>
<span class="sd">    the interaction between transformation inputs and outputs. Subclasses must</span>
<span class="sd">    implement the write_stan_operation method to define their specific</span>
<span class="sd">    mathematical operations.</span>

<span class="sd">    Shape handling can be disabled for transformations that perform reductions</span>
<span class="sd">    or other operations that fundamentally change dimensionality.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SHAPE_CHECK</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transformation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index_opts</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">assignment_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">right_side_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate complete transformation assignment code.</span>

<span class="sd">        :param index_opts: Index variable names for multi-dimensional operations</span>
<span class="sd">        :type index_opts: Optional[tuple[str, ...]]</span>
<span class="sd">        :param assignment_kwargs: Keyword arguments for assignment formatting. Defaults to None.</span>
<span class="sd">        :type assignment_kwargs: Optional[dict]</span>
<span class="sd">        :param right_side_kwargs: Keyword arguments for right-side formatting. Defaults to None.</span>
<span class="sd">        :type right_side_kwargs: Optional[dict]</span>

<span class="sd">        :returns: Complete Stan assignment statement</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        This method combines the left-hand side variable name with the right-hand</span>
<span class="sd">        side operation to create a complete Stan assignment statement suitable</span>
<span class="sd">        for use in transformed parameters or transformed data blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set defaults</span>
        <span class="n">assignment_kwargs</span> <span class="o">=</span> <span class="n">assignment_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">right_side_kwargs</span> <span class="o">=</span> <span class="n">right_side_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="c1"># Build assignment</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">get_indexed_varname</span><span class="p">(</span><span class="n">index_opts</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">assignment_kwargs</span><span class="p">)</span><span class="si">}</span><span class="s2"> = &quot;</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_right_side</span><span class="p">(</span><span class="n">index_opts</span><span class="p">,</span> <span class="o">**</span><span class="n">right_side_kwargs</span><span class="p">)</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Transformation.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Transformation.write_stan_operation">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">to_format</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for the specific transformation operation.</span>

<span class="sd">        :param to_format: Formatted parameter strings for Stan code</span>
<span class="sd">        :type to_format: str</span>

<span class="sd">        :returns: Stan code representing the mathematical operation</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        This abstract method must be implemented by all concrete transformation</span>
<span class="sd">        classes to define how their specific mathematical operation is represented</span>
<span class="sd">        in Stan code.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Transformation.get_right_side">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Transformation.get_right_side">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_right_side</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index_opts</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">start_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">end_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offset_adjustment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate right-hand side of transformation assignment.</span>

<span class="sd">        :param index_opts: Index options for multi-dimensional operations</span>
<span class="sd">        :type index_opts: Optional[tuple[str, ...]]</span>
<span class="sd">        :param start_dims: First indexable dimension of parent parameters. Defaults to None.</span>
<span class="sd">        :type start_dims: Optional[dict[str, custom_types.Integer]]</span>
<span class="sd">        :param end_dims: Last indexable dimension of parent parameters. Defaults to None.</span>
<span class="sd">        :type end_dims: Optional[dict[str, custom_types.Integer]]</span>
<span class="sd">        :param offset_adjustment: Index offset adjustment. Defaults to 0.</span>
<span class="sd">        :type offset_adjustment: int</span>

<span class="sd">        :returns: Stan code for the right-hand side of the assignment</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        This method coordinates the formatting of parent parameters and applies</span>
<span class="sd">        the transformation operation. It automatically adds parentheses around</span>
<span class="sd">        operations when the transformation is not named.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Call the inherited method to get a dictionary mapping parent names to</span>
        <span class="c1"># either their indexed variable names (if they are named) or the thread</span>
        <span class="c1"># of operations that define them (if they are not named).</span>
        <span class="n">components</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_right_side</span><span class="p">(</span>
            <span class="n">index_opts</span><span class="p">,</span>
            <span class="n">start_dims</span><span class="o">=</span><span class="n">start_dims</span><span class="p">,</span>
            <span class="n">end_dims</span><span class="o">=</span><span class="n">end_dims</span><span class="p">,</span>
            <span class="n">offset_adjustment</span><span class="o">=</span><span class="n">offset_adjustment</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Format the right-hand side of the operation. The declaration for any operation</span>
        <span class="c1"># that is not named should be wrapped in parentheses. Otherwise, exactly</span>
        <span class="c1"># how formatting is done depends on the child class.</span>
        <span class="n">stan_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="o">**</span><span class="n">components</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_named</span><span class="p">:</span>
            <span class="n">stan_op</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">stan_op</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="k">return</span> <span class="n">stan_op</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_set_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set component shape with optional shape checking bypass.</span>

<span class="sd">        Some transformations perform reductions or other operations that change</span>
<span class="sd">        dimensionality. When SHAPE_CHECK is False, automatic shape validation</span>
<span class="sd">        is bypassed to allow these operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">SHAPE_CHECK</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_set_shape</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return human-readable string representation of the transformation.</span>

<span class="sd">        :returns: String showing transformation assignment</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Creates a readable representation of the transformation for debugging</span>
<span class="sd">        and model inspection, showing the assignment operation with cleaned</span>
<span class="sd">        formatting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">right_side</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_right_side</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[start:end]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_varname</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">right_side</span><span class="si">}</span><span class="s2">&quot;</span></div>



<div class="viewcode-block" id="TransformedParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.TransformedParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformedParameter</span><span class="p">(</span><span class="n">Transformation</span><span class="p">,</span> <span class="n">TransformableParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for transformed parameters that can be used in parameter blocks.</span>

<span class="sd">    This class provides the foundation for parameters that result from mathematical</span>
<span class="sd">    operations on other parameters. It handles both the computational aspects</span>
<span class="sd">    (sampling, PyTorch operations) and code generation aspects (Stan assignments).</span>

<span class="sd">    :cvar STAN_OPERATOR: Stan operator string for simple operations</span>

<span class="sd">    Transformed parameters support:</span>
<span class="sd">    - Sampling through parent parameter sampling and operation application</span>
<span class="sd">    - PyTorch operations with automatic differentiation</span>
<span class="sd">    - Stan code generation for transformed parameters block</span>
<span class="sd">    - Further transformation through operator overloading</span>

<span class="sd">    The class provides the infrastructure for creating complex mathematical</span>
<span class="sd">    expressions while maintaining compatibility with all SciStanPy backends.</span>

<span class="sd">    Subclasses must implement:</span>
<span class="sd">    - run_np_torch_op: The core mathematical operation</span>
<span class="sd">    - write_stan_operation: Stan code generation for the operation</span>

<span class="sd">    Example Usage:</span>
<span class="sd">        TransformedParameter subclasses are typically created through operator</span>
<span class="sd">        overloading or the `operations` submodule rather than direct instantiation,</span>
<span class="sd">        but can be used directly for custom operations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="c1"># The transformation is renamed to be more specific in the child classes</span>
    <span class="n">get_transformation_assignment</span> <span class="o">=</span> <span class="n">Transformation</span><span class="o">.</span><span class="n">_transformation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_draw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">level_draws</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="s2">&quot;custom_types.Float&quot;</span><span class="p">]],</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">],</span>  <span class="c1"># pylint: disable=unused-argument</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="s2">&quot;custom_types.Float&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Draw samples by applying transformation to parent samples.</span>

<span class="sd">        :param level_draws: Samples from parent parameters</span>
<span class="sd">        :type level_draws: dict[str, Union[npt.NDArray, custom_types.Float]]</span>
<span class="sd">        :param seed: Random seed (unused for deterministic transformations)</span>
<span class="sd">        :type seed: Optional[custom_types.Integer]</span>

<span class="sd">        :returns: Transformed samples</span>
<span class="sd">        :rtype: Union[npt.NDArray, custom_types.Float]</span>

<span class="sd">        This method applies the mathematical transformation to samples drawn</span>
<span class="sd">        from parent parameters, enabling sampling from transformed distributions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Perform the operation on the draws</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="o">**</span><span class="n">level_draws</span><span class="p">)</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">draws</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">draws</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="TransformedParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.TransformedParameter.run_np_torch_op">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">draws</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute the mathematical operation using NumPy or PyTorch.</span>

<span class="sd">        :param draws: Input values for the operation</span>
<span class="sd">        :type draws: Union[torch.Tensor, custom_types.SampleType]</span>

<span class="sd">        :returns: Result of the mathematical operation</span>
<span class="sd">        :rtype: Union[torch.Tensor, npt.NDArray]</span>

<span class="sd">        This abstract method defines the core computational logic for the</span>
<span class="sd">        transformation. It must handle both NumPy and PyTorch inputs</span>
<span class="sd">        appropriately to maintain backend compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="TransformedParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.TransformedParameter.write_stan_operation">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">to_format</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for the transformation operation.</span>

<span class="sd">        :param to_format: Formatted parameter strings</span>
<span class="sd">        :type to_format: str</span>

<span class="sd">        :returns: Stan code for the operation</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        :raises NotImplementedError: If STAN_OPERATOR is not defined for simple operations</span>

<span class="sd">        This method must be implemented to provide appropriate Stan code</span>
<span class="sd">        for the mathematical operation represented by this transformation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The Stan operator must be defined in the child class</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">STAN_OPERATOR</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The STAN_OPERATOR must be defined.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="s2">&quot;&quot;</span></div>


    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Enable calling transformed parameters as functions.</span>

<span class="sd">        :param args: Positional arguments passed to run_np_torch_op</span>
<span class="sd">        :param kwargs: Keyword arguments passed to run_np_torch_op</span>

<span class="sd">        :returns: Result of the operation</span>

<span class="sd">        This allows transformed parameters to be used as callable functions,</span>
<span class="sd">        providing a convenient interface for applying operations directly.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">torch_parametrization</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get PyTorch representation with transformations applied.</span>

<span class="sd">        :returns: PyTorch tensor with operation applied to parent tensors</span>
<span class="sd">        :rtype: torch.Tensor</span>

<span class="sd">        This property applies the transformation operation to the PyTorch</span>
<span class="sd">        parameterizations of all parent parameters, maintaining gradient</span>
<span class="sd">        flow for optimization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This is just the operation performed on the torch parameters of the parents</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span>
            <span class="o">**</span><span class="p">{</span>
                <span class="n">name</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">torch_parametrization</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parents</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="BinaryTransformedParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryTransformedParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BinaryTransformedParameter</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for transformations involving exactly two parameters.</span>

<span class="sd">    This class provides a specialized interface for binary mathematical operations</span>
<span class="sd">    such as addition, subtraction, multiplication, and division. It enforces the</span>
<span class="sd">    two-parameter constraint and provides appropriate method signatures.</span>

<span class="sd">    :param dist1: First parameter for the operation</span>
<span class="sd">    :type dist1: custom_types.CombinableParameterType</span>
<span class="sd">    :param dist2: Second parameter for the operation</span>
<span class="sd">    :type dist2: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Binary operations are the foundation for arithmetic expressions and provide</span>
<span class="sd">    the building blocks for more complex mathematical relationships between</span>
<span class="sd">    parameters.</span>

<span class="sd">    Subclasses must implement run_np_torch_op with the (dist1, dist2) signature</span>
<span class="sd">    and can optionally override write_stan_operation for custom Stan formatting.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dist1</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">dist2</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dist1</span><span class="o">=</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="o">=</span><span class="n">dist2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dist2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span> <span class="n">dist2</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="BinaryTransformedParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryTransformedParameter.run_np_torch_op">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute binary operation on two inputs.</span>

<span class="sd">        :param dist1: First operand</span>
<span class="sd">        :param dist2: Second operand</span>

<span class="sd">        :returns: Result of binary operation</span>

<span class="sd">        This method implements the core binary mathematical operation</span>
<span class="sd">        for both NumPy and PyTorch backends.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="BinaryTransformedParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryTransformedParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dist2</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for binary operations using STAN_OPERATOR.</span>

<span class="sd">        :param dist1: Formatted string for first parameter</span>
<span class="sd">        :type dist1: str</span>
<span class="sd">        :param dist2: Formatted string for second parameter</span>
<span class="sd">        :type dist2: str</span>

<span class="sd">        :returns: Stan code with infix operator</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Generates Stan code in the format &quot;dist1 OPERATOR dist2&quot; for</span>
<span class="sd">        standard binary operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">()</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">STAN_OPERATOR</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">dist2</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>


    <span class="c1"># pylint: enable=arguments-differ</span>


<div class="viewcode-block" id="UnaryTransformedParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.UnaryTransformedParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">UnaryTransformedParameter</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for transformations involving exactly one parameter.</span>

<span class="sd">    This class provides a specialized interface for unary mathematical operations</span>
<span class="sd">    such as negation, absolute value, logarithms, and exponentials. It enforces</span>
<span class="sd">    the single-parameter constraint and provides appropriate method signatures.</span>

<span class="sd">    :param dist1: Parameter for the operation</span>
<span class="sd">    :type dist1: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Unary operations are essential for mathematical transformations and provide</span>
<span class="sd">    common functions needed in statistical modeling and parameter reparameterization.</span>

<span class="sd">    Subclasses must implement run_np_torch_op with the single-parameter signature</span>
<span class="sd">    and can optionally override write_stan_operation for custom Stan formatting.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dist1</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dist1</span><span class="o">=</span><span class="n">dist1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="UnaryTransformedParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.UnaryTransformedParameter.run_np_torch_op">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute unary operation on single input.</span>

<span class="sd">        :param dist1: Input operand</span>

<span class="sd">        :returns: Result of unary operation</span>

<span class="sd">        This method implements the core unary mathematical operation</span>
<span class="sd">        for both NumPy and PyTorch backends.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="UnaryTransformedParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.UnaryTransformedParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for unary operations using STAN_OPERATOR.</span>

<span class="sd">        :param dist1: Formatted string for the parameter</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan code with prefix operator</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Generates Stan code in the format &quot;OPERATOR dist1&quot; for</span>
<span class="sd">        standard unary operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">()</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">STAN_OPERATOR</span><span class="si">}{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>


    <span class="c1"># pylint: enable=arguments-differ</span>


<span class="c1"># Basic arithmetic operations</span>
<div class="viewcode-block" id="AddParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.AddParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AddParameter</span><span class="p">(</span><span class="n">BinaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Addition transformation for two parameters.</span>

<span class="sd">    Implements element-wise addition of two parameters: result = dist1 + dist2</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Commutative: a + b = b + a</span>
<span class="sd">    - Associative: (a + b) + c = a + (b + c)</span>
<span class="sd">    - Identity element: 0</span>

<span class="sd">    This transformation preserves the shape through broadcasting and is commonly</span>
<span class="sd">    used for combining effects, offsets, and linear combinations of parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;+&quot;</span>

<div class="viewcode-block" id="AddParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.AddParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise addition.</span>

<span class="sd">        :param dist1: First addend</span>
<span class="sd">        :param dist2: Second addend</span>

<span class="sd">        :returns: Sum of the two inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist1</span> <span class="o">+</span> <span class="n">dist2</span></div>
</div>



<div class="viewcode-block" id="SubtractParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SubtractParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SubtractParameter</span><span class="p">(</span><span class="n">BinaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subtraction transformation for two parameters.</span>

<span class="sd">    Implements element-wise subtraction of two parameters: result = dist1 - dist2</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Non-commutative: a - b ≠ b - a (generally)</span>
<span class="sd">    - Non-associative: (a - b) - c ≠ a - (b - c) (generally)</span>
<span class="sd">    - Identity element: 0 (for right operand)</span>

<span class="sd">    This transformation is commonly used for computing differences, residuals,</span>
<span class="sd">    and relative measures between parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;-&quot;</span>

<div class="viewcode-block" id="SubtractParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SubtractParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise subtraction.</span>

<span class="sd">        :param dist1: Minuend</span>
<span class="sd">        :param dist2: Subtrahend</span>

<span class="sd">        :returns: Difference of the two inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist1</span> <span class="o">-</span> <span class="n">dist2</span></div>
</div>



<div class="viewcode-block" id="MultiplyParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.MultiplyParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiplyParameter</span><span class="p">(</span><span class="n">BinaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Element-wise multiplication transformation for two parameters.</span>

<span class="sd">    Implements element-wise multiplication of two parameters: result = dist1 * dist2</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Commutative: a * b = b * a</span>
<span class="sd">    - Associative: (a * b) * c = a * (b * c)</span>
<span class="sd">    - Identity element: 1</span>

<span class="sd">    This transformation is fundamental for scaling, interaction effects, and</span>
<span class="sd">    product relationships between parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.*&quot;</span>

<div class="viewcode-block" id="MultiplyParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.MultiplyParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise multiplication.</span>

<span class="sd">        :param dist1: First factor</span>
<span class="sd">        :param dist2: Second factor</span>

<span class="sd">        :returns: Product of the two inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist1</span> <span class="o">*</span> <span class="n">dist2</span></div>
</div>



<div class="viewcode-block" id="DivideParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.DivideParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DivideParameter</span><span class="p">(</span><span class="n">BinaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Element-wise division transformation for two parameters.</span>

<span class="sd">    Implements element-wise division of two parameters: result = dist1 / dist2</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Non-commutative: a / b ≠ b / a (generally)</span>
<span class="sd">    - Non-associative: (a / b) / c ≠ a / (b / c) (generally)</span>
<span class="sd">    - Identity element: 1 (for right operand)</span>

<span class="sd">    This transformation is used for ratios, rates, normalized quantities,</span>
<span class="sd">    and relative measures. Care must be taken to avoid division by zero.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;./&quot;</span>

<div class="viewcode-block" id="DivideParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.DivideParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise division.</span>

<span class="sd">        :param dist1: Dividend</span>
<span class="sd">        :param dist2: Divisor</span>

<span class="sd">        :returns: Quotient of the two inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist1</span> <span class="o">/</span> <span class="n">dist2</span></div>
</div>



<div class="viewcode-block" id="PowerParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.PowerParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PowerParameter</span><span class="p">(</span><span class="n">BinaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Element-wise exponentiation transformation for two parameters.</span>

<span class="sd">    Implements element-wise exponentiation: result = dist1 ^ dist2</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Non-commutative: a^b ≠ b^a (generally)</span>
<span class="sd">    - Non-associative: (a^b)^c ≠ a^(b^c) (generally)</span>
<span class="sd">    - Identity element: 1 (for exponent), any base^1 = base</span>

<span class="sd">    This transformation is used for power relationships, polynomial terms,</span>
<span class="sd">    and exponential scaling effects.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.^&quot;</span>

<div class="viewcode-block" id="PowerParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.PowerParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise exponentiation.</span>

<span class="sd">        :param dist1: Base</span>
<span class="sd">        :param dist2: Exponent</span>

<span class="sd">        :returns: dist1 raised to the power of dist2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist1</span><span class="o">**</span><span class="n">dist2</span></div>
</div>



<div class="viewcode-block" id="NegateParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NegateParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NegateParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unary negation transformation for parameters.</span>

<span class="sd">    Implements element-wise negation of a parameter: result = -dist1</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Involutory: -(-a) = a</span>
<span class="sd">    - Distributive over addition: -(a + b) = -a + -b</span>
<span class="sd">    - Anti-distributive over multiplication: -(a * b) = (-a) * b = a * (-b)</span>

<span class="sd">    This transformation is used for sign changes, directional effects,</span>
<span class="sd">    and creating opposite relationships.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STAN_OPERATOR</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;-&quot;</span>

<div class="viewcode-block" id="NegateParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NegateParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform element-wise negation.</span>

<span class="sd">        :param dist1: Input parameter</span>

<span class="sd">        :returns: Negated input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">dist1</span></div>
</div>



<div class="viewcode-block" id="AbsParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.AbsParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AbsParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Absolute value transformation for parameters.</span>

<span class="sd">    Implements element-wise absolute value: result = \|dist1\|</span>

<span class="sd">    :cvar LOWER_BOUND: Absolute values are always non-negative (0.0)</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Non-negative output: \|a\| ≥ 0</span>
<span class="sd">    - Idempotent for non-negative inputs: \|\|a\|\| = \|a\|</span>
<span class="sd">    - Triangle inequality: \|a + b\| ≤ \|a\| + \|b\|</span>

<span class="sd">    This transformation ensures non-negative values and is commonly used</span>
<span class="sd">    for magnitudes, distances, and ensuring positive parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>

<div class="viewcode-block" id="AbsParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.AbsParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute element-wise absolute value.</span>

<span class="sd">        :param dist1: Input parameter</span>

<span class="sd">        :returns: Absolute value of input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbsParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.AbsParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan absolute value function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan abs() function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;abs(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="LogParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Natural logarithm transformation for parameters.</span>

<span class="sd">    Implements element-wise natural logarithm: result = ln(dist1)</span>

<span class="sd">    :cvar POSITIVE_PARAMS: Input must be positive ({&quot;dist1&quot;})</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: (0, ∞)</span>
<span class="sd">    - Range: (-∞, ∞)</span>
<span class="sd">    - Logarithm laws: ln(ab) = ln(a) + ln(b), ln(a^b) = b*ln(a)</span>
<span class="sd">    - Inverse: exp(ln(a)) = a for a &gt; 0</span>

<span class="sd">    This transformation is fundamental for log-scale modeling, multiplicative</span>
<span class="sd">    effects on additive scales, and ensuring positive-valued parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">POSITIVE_PARAMS</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dist1&quot;</span><span class="p">}</span>

<div class="viewcode-block" id="LogParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute element-wise natural logarithm.</span>

<span class="sd">        :param dist1: Input parameter (must be positive)</span>

<span class="sd">        :returns: Natural logarithm of input</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span></div>


<div class="viewcode-block" id="LogParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan logarithm function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan log() function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;log(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="ExpParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExpParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ExpParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Exponential transformation for parameters.</span>

<span class="sd">    Implements element-wise exponential function: result = exp(dist1)</span>

<span class="sd">    :cvar LOWER_BOUND: Exponential values are always positive (0.0)</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: (-∞, ∞)</span>
<span class="sd">    - Range: (0, ∞)</span>
<span class="sd">    - Exponential laws: exp(a+b) = exp(a)*exp(b), exp(a*b) ≠ exp(a)*exp(b)</span>
<span class="sd">    - Inverse: ln(exp(a)) = a</span>

<span class="sd">    This transformation is used for ensuring positive values, exponential</span>
<span class="sd">    growth models, and converting from log-scale to natural scale.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>

<div class="viewcode-block" id="ExpParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExpParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span></div>


<div class="viewcode-block" id="ExpParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExpParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan exponential function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan exp() function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;exp(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="NormalizeParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NormalizeParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalization transformation that scales values to sum to 1 in the last dimension</span>
<span class="sd">    of the input.</span>

<span class="sd">    Implements element-wise normalization where each vector is divided by its sum,</span>
<span class="sd">    creating probability vectors or normalized weights that sum to unity.</span>

<span class="sd">    :cvar LOWER_BOUND: Normalized values are non-negative (0.0)</span>
<span class="sd">    :cvar UPPER_BOUND: Normalized values are bounded above by 1.0</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: [0, ∞)^n (non-negative input required)</span>
<span class="sd">    - Range: Probability simplex {x : Σxᵢ = 1, xᵢ ≥ 0}</span>
<span class="sd">    - Operation: xᵢ&#39; = xᵢ / Σⱼ xⱼ</span>
<span class="sd">    - Preserves ratios between elements</span>

<span class="sd">    This transformation is essential for:</span>
<span class="sd">    - Converting counts to proportions</span>
<span class="sd">    - Creating probability vectors from non-negative weights</span>
<span class="sd">    - Normalizing attention weights or mixture components</span>
<span class="sd">    - Ensuring categorical probabilities sum to one</span>

<span class="sd">    The normalization is applied along the last dimension only, making it suitable</span>
<span class="sd">    for batch processing of multiple probability vectors.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">1.0</span>

<div class="viewcode-block" id="NormalizeParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute normalization by dividing by sum along last dimension.</span>

<span class="sd">        :param dist1: Input parameter (must be non-negative)</span>

<span class="sd">        :returns: Normalized values that sum to 1 along last dimension</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">dist1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">dist1</span> <span class="o">/</span> <span class="n">dist1</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Error if the type is not supported</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported type for dist1. Expected torch.Tensor or np.ndarray.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NormalizeParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan normalization code.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan code dividing by sum</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2"> / sum(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="NormalizeLogParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeLogParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NormalizeLogParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-space normalization transformation for log-probability vectors over the</span>
<span class="sd">    last dimension of the input.</span>

<span class="sd">    Implements normalization in log-space where log-probabilities are adjusted</span>
<span class="sd">    so that their exponentiated values sum to 1. This is equivalent to</span>
<span class="sd">    subtracting the log-sum-exp from each element.</span>

<span class="sd">    :cvar UPPER_BOUND: Log-probabilities are bounded above by 0.0</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: (-∞, ∞)^n</span>
<span class="sd">    - Range: Log-simplex {x : Σexp(xᵢ) = 1}</span>
<span class="sd">    - Operation: xᵢ&#39; = xᵢ - log(Σⱼ exp(xⱼ))</span>
<span class="sd">    - Numerically stable for extreme log-probabilities</span>

<span class="sd">    This transformation is crucial for:</span>
<span class="sd">    - Normalizing log-probabilities without exponentiation</span>
<span class="sd">    - Stable computation with very small probabilities</span>
<span class="sd">    - Log-space categorical distributions</span>
<span class="sd">    - Attention mechanisms in log-space</span>

<span class="sd">    The log-sum-exp operation provides numerical stability by avoiding</span>
<span class="sd">    overflow/underflow issues common with direct exponentiation. As with the `NormalizeParameter`,</span>
<span class="sd">    this is performed over the last dimension only.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>

<div class="viewcode-block" id="NormalizeLogParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeLogParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-space normalization using log-sum-exp.</span>

<span class="sd">        :param dist1: Input log-probabilities</span>

<span class="sd">        :returns: Normalized log-probabilities</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">dist1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">dist1</span> <span class="o">-</span> <span class="n">sp</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported type for dist1. Expected torch.Tensor or np.ndarray.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NormalizeLogParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.NormalizeLogParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan log-space normalization code.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan code using log_sum_exp function</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2"> - log_sum_exp(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="Reduction">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Reduction">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Reduction</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for operations that reduce dimensionality.</span>

<span class="sd">    This abstract base class provides infrastructure for transformations that</span>
<span class="sd">    reduce the size of the last dimension through operations like sum, mean,</span>
<span class="sd">    or log-sum-exp. It handles shape management and provides specialized</span>
<span class="sd">    indexing behavior for reductions.</span>

<span class="sd">    :cvar SHAPE_CHECK: Disabled for reductions (False)</span>
<span class="sd">    :cvar TORCH_FUNC: PyTorch function for the reduction operation</span>
<span class="sd">    :cvar NP_FUNC: NumPy function for the reduction operation</span>

<span class="sd">    :param dist1: Parameter to reduce</span>
<span class="sd">    :type dist1: custom_types.CombinableParameterType</span>
<span class="sd">    :param keepdims: Whether to keep the reduced dimension as size 1. Defaults to False.</span>
<span class="sd">    :type keepdims: bool</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Key Features:</span>
<span class="sd">    - Automatic shape calculation for reduced dimensions</span>
<span class="sd">    - Specialized index offset handling (always returns 0)</span>
<span class="sd">    - Increased assignment depth for proper Stan loop structure</span>
<span class="sd">    - Support for keepdims option to preserve dimensionality</span>

<span class="sd">    Subclasses must define TORCH_FUNC and NP_FUNC class variables that</span>
<span class="sd">    point to the appropriate reduction functions in each library.</span>

<span class="sd">    Example:</span>
<span class="sd">        Subclasses like SumParameter and LogSumExpParameter inherit from</span>
<span class="sd">        this base class and define their specific reduction operations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SHAPE_CHECK</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">TORCH_FUNC</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">],</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">]</span>
    <span class="n">NP_FUNC</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">],</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dist1</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">keepdims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize reduction with automatic shape calculation. Reduction is always</span>
<span class="sd">        over the last dimension.</span>

<span class="sd">        :param dist1: Parameter to reduce</span>
<span class="sd">        :type dist1: custom_types.CombinableParameterType</span>
<span class="sd">        :param keepdims: Whether to keep reduced dimension. Defaults to False.</span>
<span class="sd">        :type keepdims: bool</span>
<span class="sd">        :param kwargs: Additional arguments for parent initialization</span>

<span class="sd">        The initialization automatically calculates the output shape by</span>
<span class="sd">        removing the last dimension (or keeping it as size 1 if keepdims=True).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Record whether to keep the last dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keepdims</span> <span class="o">=</span> <span class="n">keepdims</span>

        <span class="c1"># The shape is the leading dimensions of the input parameter plus a singleton</span>
        <span class="c1"># dimension if keepdims is True.</span>
        <span class="k">if</span> <span class="s2">&quot;shape&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">dist1</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span>

        <span class="c1"># Init as normal</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dist1</span><span class="o">=</span><span class="n">dist1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="Reduction.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Reduction.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute reduction operation with backend-appropriate function.</span>

<span class="sd">        :param dist1: Input parameter to reduce</span>
<span class="sd">        :param keepdim: Whether to keep dimensions (static method only)</span>
<span class="sd">        :type keepdim: Optional[bool]</span>

<span class="sd">        :returns: Reduced parameter values</span>

<span class="sd">        :raises ValueError: If keepdim is provided for instance method calls</span>

<span class="sd">        The method automatically selects between PyTorch and NumPy reduction</span>
<span class="sd">        functions and applies them along the last dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Keepdim can only be provided if called as a static method</span>
        <span class="k">if</span> <span class="bp">self</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keepdim</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">keepdim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">keepdim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The `keepdim` argument can only be provided when calling this method &quot;</span>
                <span class="s2">&quot;as a static method.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">keepdim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">keepdims</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">TORCH_FUNC</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">NP_FUNC</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdim</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="Reduction.get_index_offset">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Reduction.get_index_offset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_index_offset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;abstract_model_component.AbstractModelComponent&quot;</span><span class="p">],</span>
        <span class="n">offset_adjustment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return zero offset for all reduction operations.</span>

<span class="sd">        :param query: Component or parameter name (ignored)</span>
<span class="sd">        :param offset_adjustment: Offset adjustment (ignored)</span>

<span class="sd">        :returns: Always returns 0</span>
<span class="sd">        :rtype: int</span>

<span class="sd">        Reductions always return zero offset because they operate on the</span>
<span class="sd">        last dimension and don&#39;t require complex indexing adjustments.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span></div>


<div class="viewcode-block" id="Reduction.get_assign_depth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Reduction.get_assign_depth">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_assign_depth</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return assignment depth one level higher than normal.</span>

<span class="sd">        :returns: Assignment depth + 1</span>
<span class="sd">        :rtype: int</span>

<span class="sd">        Reductions require one additional level of loop nesting to properly</span>
<span class="sd">        iterate over the dimension being reduced.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_assign_depth</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span></div>
</div>



<div class="viewcode-block" id="LogSumExpParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSumExpParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogSumExpParameter</span><span class="p">(</span><span class="n">Reduction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-sum-exp reduction transformation.</span>

<span class="sd">    Computes the logarithm of the sum of exponentials along the last dimension,</span>
<span class="sd">    providing a numerically stable way to compute log(Σᵢ exp(xᵢ)).</span>

<span class="sd">    :cvar TORCH_FUNC: torch.logsumexp</span>
<span class="sd">    :cvar NP_FUNC: scipy.special.logsumexp</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Operation: log(Σᵢ exp(xᵢ))</span>
<span class="sd">    - Numerically stable for extreme values</span>
<span class="sd">    - Maintains precision in log-space</span>
<span class="sd">    - Essential for probabilistic computations</span>

<span class="sd">    This transformation is fundamental for:</span>
<span class="sd">    - Normalizing log-probabilities</span>
<span class="sd">    - Computing partition functions</span>
<span class="sd">    - Stable softmax computations</span>
<span class="sd">    - Log-space mixture models</span>

<span class="sd">    The log-sum-exp function is the smooth maximum approximation and</span>
<span class="sd">    appears frequently in machine learning and statistics.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; log_weights = LogParameter(weights)</span>
<span class="sd">        &gt;&gt;&gt; log_partition = LogSumExpParameter(log_weights)</span>
<span class="sd">        &gt;&gt;&gt; normalized_log_weights = log_weights - log_partition</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">TORCH_FUNC</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span>
    <span class="n">NP_FUNC</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">logsumexp</span>

<div class="viewcode-block" id="LogSumExpParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSumExpParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan log_sum_exp function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan log_sum_exp function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;log_sum_exp(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="SumParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SumParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SumParameter</span><span class="p">(</span><span class="n">Reduction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sum reduction transformation.</span>

<span class="sd">    Computes the sum of values along the last dimension: Σᵢ xᵢ</span>

<span class="sd">    :cvar TORCH_FUNC: torch.sum</span>
<span class="sd">    :cvar NP_FUNC: numpy.sum</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Operation: Σᵢ xᵢ</span>
<span class="sd">    - Linear operation</span>
<span class="sd">    - Preserves units and scale</span>
<span class="sd">    - Fundamental aggregation operation</span>

<span class="sd">    This transformation is used for:</span>
<span class="sd">    - Computing totals and aggregates</span>
<span class="sd">    - Reducing dimensionality through summation</span>
<span class="sd">    - Calculating marginal quantities</span>
<span class="sd">    - Creating scalar summaries from vectors</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; category_counts = Poisson(lambda_=rates)</span>
<span class="sd">        &gt;&gt;&gt; total_count = SumParameter(category_counts)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">TORCH_FUNC</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span>
    <span class="n">NP_FUNC</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span>

<div class="viewcode-block" id="SumParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SumParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan sum function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan sum function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;sum(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="Log1pExpParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Log1pExpParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Log1pExpParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log(1 + exp(x)) transformation with numerical stability.</span>

<span class="sd">    Computes log(1 + exp(x)) using numerically stable implementations that</span>
<span class="sd">    avoid overflow for large positive values and underflow for large negative values.</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: (-∞, ∞)</span>
<span class="sd">    - Range: [0, ∞)</span>
<span class="sd">    - Smooth approximation to max(0, x)</span>
<span class="sd">    - Also known as &quot;softplus&quot; function</span>

<span class="sd">    This transformation is essential for:</span>
<span class="sd">    - Numerical stability in probabilistic models</span>
<span class="sd">    - Log-space computations avoiding direct exponentiation</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; log_odds = Normal(mu=0, sigma=1)</span>
<span class="sd">        &gt;&gt;&gt; log_prob = Log1pExpParameter(log_odds)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Log1pExpParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Log1pExpParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log(1 + exp(x)) with numerical stability.</span>

<span class="sd">        :param dist1: Input parameter</span>

<span class="sd">        :returns: log(1 + exp(dist1))</span>

<span class="sd">        Uses logaddexp(0, x) for numerical stability, which handles</span>
<span class="sd">        both overflow (large positive x) and underflow (large negative x).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If using torch, use the logaddexp function directly.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dist1</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">dist1</span><span class="p">)</span>
        <span class="c1"># If using numpy, use the logaddexp function from scipy.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dist1</span><span class="p">)</span>
        <span class="c1"># Error if the type is not supported</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported type for dist1. Expected torch.Tensor or np.ndarray.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="Log1pExpParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.Log1pExpParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan log1p_exp function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan log1p_exp function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;log1p_exp(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="SigmoidParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SigmoidParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sigmoid (logistic) transformation for parameters.</span>

<span class="sd">    Implements the sigmoid function: result = 1 / (1 + exp(-dist1))</span>

<span class="sd">    :cvar LOWER_BOUND: Sigmoid values are bounded below by 0.0</span>
<span class="sd">    :cvar UPPER_BOUND: Sigmoid values are bounded above by 1.0</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Domain: (-∞, ∞)</span>
<span class="sd">    - Range: (0, 1)</span>
<span class="sd">    - S-shaped curve with inflection point at x=0, y=0.5</span>
<span class="sd">    - Inverse: logit function ln(p/(1-p))</span>

<span class="sd">    The sigmoid function is essential for:</span>
<span class="sd">    - Converting unbounded values to probabilities</span>
<span class="sd">    - Logistic regression and classification</span>
<span class="sd">    - Smooth transitions between bounds</span>
<span class="sd">    - Activation functions in neural networks</span>

<span class="sd">    This implementation uses numerically stable computation methods to</span>
<span class="sd">    avoid overflow/underflow issues.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>

<div class="viewcode-block" id="SigmoidParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute sigmoid function with numerical stability.</span>

<span class="sd">        :param dist1: Input parameter (logits)</span>

<span class="sd">        :returns: Sigmoid-transformed values in (0, 1)</span>
<span class="sd">        :rtype: Union[torch.Tensor, np.ndarray]</span>

<span class="sd">        :raises TypeError: If input type is not supported</span>

<span class="sd">        Uses numerically stable implementations:</span>
<span class="sd">        - PyTorch: Built-in torch.sigmoid function</span>
<span class="sd">        - NumPy: Custom stable implementation from utils</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If using torch, use the sigmoid function directly.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span>

        <span class="c1"># If using numpy, we manually calculate the sigmoid function using a more</span>
        <span class="c1"># numerically stable approach.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">stable_sigmoid</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span>

        <span class="c1"># If using a different type, raise an error.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported type for dist1. Expected torch.Tensor or np.ndarray.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="SigmoidParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan inverse logit function call.</span>

<span class="sd">        :param dist1: Formatted parameter string</span>
<span class="sd">        :type dist1: str</span>

<span class="sd">        :returns: Stan inv_logit() function call</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;inv_logit(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="LogSigmoidParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogSigmoidParameter</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Defines a parameter that is the log of the sigmoid of another.&quot;&quot;&quot;</span>

    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>

<div class="viewcode-block" id="LogSigmoidParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="n">dist1</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">stable_sigmoid</span><span class="p">(</span><span class="n">dist1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported type for dist1. Expected torch.Tensor or np.ndarray.&quot;</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="LogSigmoidParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist1</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;log_inv_logit(</span><span class="si">{</span><span class="n">dist1</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</div>



<div class="viewcode-block" id="ExponentialGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExponentialGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ExponentialGrowth</span><span class="p">(</span><span class="n">ExpParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A transformed parameter that models exponential growth. Specifically, parameters</span>
<span class="sd">    `t`, `A`, and `r` are used to calculate the exponential growth model as follows:</span>

<span class="sd">    $$</span>
<span class="sd">    x = A\textrm{e}^{rt)</span>
<span class="sd">    $$</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize exponential growth model.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param A: Amplitude parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="ExponentialGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExponentialGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute exponential growth: A * exp(r * t).</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param A: Amplitude values</span>
<span class="sd">        :param r: Rate values</span>

<span class="sd">        :returns: Exponential growth values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">ExpParameter</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span></div>


    <span class="c1"># pylint: enable=arguments-differ</span>

<div class="viewcode-block" id="ExponentialGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ExponentialGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">par_string</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">A</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">par_string</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="BinaryExponentialGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryExponentialGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BinaryExponentialGrowth</span><span class="p">(</span><span class="n">ExpParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Binary exponential growth for two time points.</span>

<span class="sd">    Special case of exponential growth for modeling with only two time points,</span>
<span class="sd">    assuming t₀ = 0 and t₁ = 1. This reduces to: x = A * exp(r)</span>

<span class="sd">    :param A: Amplitude parameter (value at t=0)</span>
<span class="sd">    :type A: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Simplified exponential model for binary time points</span>
<span class="sd">    - A represents initial value</span>
<span class="sd">    - exp(r) represents fold-change from t=0 to t=1</span>
<span class="sd">    - r is log-fold-change</span>

<span class="sd">    This transformation is useful for:</span>
<span class="sd">    - Before/after comparisons</span>
<span class="sd">    - Treatment effect modeling</span>
<span class="sd">    - Two-timepoint studies</span>
<span class="sd">    - Fold-change analysis</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; baseline = Normal(mu=100, sigma=10)</span>
<span class="sd">        &gt;&gt;&gt; log_fold_change = Normal(mu=0, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; final_value = BinaryExponentialGrowth(A=baseline, r=log_fold_change)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize binary exponential growth.</span>

<span class="sd">        :param A: Amplitude parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>
<div class="viewcode-block" id="BinaryExponentialGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryExponentialGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute binary exponential growth: A * exp(r).</span>

<span class="sd">        :param A: Amplitude values</span>
<span class="sd">        :param r: Rate values</span>

<span class="sd">        :returns: A * exp(r)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">ExpParameter</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span></div>


<div class="viewcode-block" id="BinaryExponentialGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryExponentialGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for binary exponential growth.</span>

<span class="sd">        :param A: Formatted amplitude parameter</span>
<span class="sd">        :type A: str</span>
<span class="sd">        :param r: Formatted rate parameter</span>
<span class="sd">        :type r: str</span>

<span class="sd">        :returns: Stan code for A .* exp(r)</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">A</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="LogExponentialGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogExponentialGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogExponentialGrowth</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-scale exponential growth model transformation.</span>

<span class="sd">    Implements the logarithm of exponential growth: log(x) = log_A + r * t</span>

<span class="sd">    :param t: Time parameter</span>
<span class="sd">    :type t: custom_types.CombinableParameterType</span>
<span class="sd">    :param log_A: Log-amplitude parameter (log of initial value)</span>
<span class="sd">    :type log_A: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Linear in log-space: log(x) = log_A + r * t</span>
<span class="sd">    - Guaranteed positive output: x = exp(log_A + r * t) &gt; 0</span>
<span class="sd">    - Growth rate r directly additive in log-space</span>
<span class="sd">    - Natural for multiplicative processes</span>

<span class="sd">    This transformation is particularly useful for:</span>
<span class="sd">    - Population modeling where values must be positive</span>
<span class="sd">    - Multiplicative growth processes</span>
<span class="sd">    - Log-scale regression models</span>
<span class="sd">    - Ensuring positive-valued outcomes</span>

<span class="sd">    The log-scale parameterization avoids issues with negative values</span>
<span class="sd">    and provides numerical stability for extreme growth rates.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; time_points = Constant([0, 1, 2, 3])</span>
<span class="sd">        &gt;&gt;&gt; log_initial_pop = Normal(mu=4.6, sigma=0.1)  # log(100) ≈ 4.6</span>
<span class="sd">        &gt;&gt;&gt; growth_rate = Normal(mu=0.1, sigma=0.02)</span>
<span class="sd">        &gt;&gt;&gt; log_population = LogExponentialGrowth(t=time_points, log_A=log_initial_pop,</span>
<span class="sd">        &gt;&gt;&gt;                                         r=growth_rate)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize log-exponential growth model.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param log_A: Log-amplitude parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">log_A</span><span class="o">=</span><span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="LogExponentialGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogExponentialGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-exponential growth: log_A + r * t.</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param log_A: Log-amplitude values</span>
<span class="sd">        :param r: Rate values</span>

<span class="sd">        :returns: Log-exponential growth values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">log_A</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">t</span></div>


    <span class="c1"># pylint: enable=arguments-differ</span>

<div class="viewcode-block" id="LogExponentialGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogExponentialGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">log_A</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="BinaryLogExponentialGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryLogExponentialGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BinaryLogExponentialGrowth</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Binary log-exponential growth for two time points.</span>

<span class="sd">    Special case of log-exponential growth for two time points,</span>
<span class="sd">    reducing to: log(x) = log_A + r</span>

<span class="sd">    :param log_A: Log-amplitude parameter (log of initial value)</span>
<span class="sd">    :type log_A: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Simple additive model in log-space</span>
<span class="sd">    - r represents log-fold-change</span>
<span class="sd">    - Guaranteed positive output when exponentiated</span>
<span class="sd">    - Linear relationship in log-scale</span>

<span class="sd">    This transformation is ideal for:</span>
<span class="sd">    - Binary treatment effects in log-space</span>
<span class="sd">    - Fold-change modeling</span>
<span class="sd">    - Two-timepoint growth analysis</span>
<span class="sd">    - Log-scale before/after comparisons</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; log_baseline = Normal(mu=4.6, sigma=0.1)  # log(100)</span>
<span class="sd">        &gt;&gt;&gt; log_fold_change = Normal(mu=0, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; log_final = BinaryLogExponentialGrowth(log_A=log_baseline, r=log_fold_change)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize binary log-exponential growth.</span>

<span class="sd">        :param log_A: Log-amplitude parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">log_A</span><span class="o">=</span><span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>
<div class="viewcode-block" id="BinaryLogExponentialGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryLogExponentialGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute binary log-exponential growth: log_A + r.</span>

<span class="sd">        :param log_A: Log-amplitude values</span>
<span class="sd">        :param r: Rate values</span>

<span class="sd">        :returns: log_A + r</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">log_A</span> <span class="o">+</span> <span class="n">r</span></div>


<div class="viewcode-block" id="BinaryLogExponentialGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.BinaryLogExponentialGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan code for binary log-exponential growth.</span>

<span class="sd">        :param log_A: Formatted log-amplitude parameter</span>
<span class="sd">        :type log_A: str</span>
<span class="sd">        :param r: Formatted rate parameter</span>
<span class="sd">        :type r: str</span>

<span class="sd">        :returns: Stan code for log_A + r</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">log_A</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="SigmoidGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SigmoidGrowth</span><span class="p">(</span><span class="n">SigmoidParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sigmoid growth model transformation.</span>

<span class="sd">    Implements sigmoid growth: x = A / (1 + exp(-r*(t - c)))</span>
<span class="sd">    This models S-shaped growth curves with carrying capacity A.</span>

<span class="sd">    :param t: Time parameter</span>
<span class="sd">    :type t: custom_types.CombinableParameterType</span>
<span class="sd">    :param A: Amplitude parameter (carrying capacity)</span>
<span class="sd">    :type A: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param c: Inflection point parameter (time of fastest growth)</span>
<span class="sd">    :type c: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    :cvar LOWER_BOUND: Values are bounded below by 0.0</span>
<span class="sd">    :cvar UPPER_BOUND: No upper bound (None) as A can be any positive value</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - S-shaped growth curve</span>
<span class="sd">    - A represents carrying capacity (maximum value)</span>
<span class="sd">    - c represents inflection point (time of fastest growth)</span>
<span class="sd">    - r controls steepness of growth</span>
<span class="sd">    - Approaches 0 as t → -∞ and A as t → +∞</span>

<span class="sd">    This transformation is essential for:</span>
<span class="sd">    - Population growth with carrying capacity</span>
<span class="sd">    - Any growth process with saturation</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; time_points = Constant(np.linspace(0, 10, 100))</span>
<span class="sd">        &gt;&gt;&gt; carrying_capacity = Normal(mu=1000, sigma=50)</span>
<span class="sd">        &gt;&gt;&gt; growth_rate = Normal(mu=1.0, sigma=0.1)</span>
<span class="sd">        &gt;&gt;&gt; inflection_time = Normal(mu=5.0, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; population = SigmoidGrowth(t=time_points, A=carrying_capacity,</span>
<span class="sd">        &gt;&gt;&gt;                             r=growth_rate, c=inflection_time)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize sigmoid growth model.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param A: Amplitude/carrying capacity parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param c: Inflection point parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="SigmoidGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute sigmoid growth: A * sigmoid(r * (t - c)).</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param A: Amplitude values</span>
<span class="sd">        :param r: Rate values</span>
<span class="sd">        :param c: Inflection point values</span>

<span class="sd">        :returns: Sigmoid growth values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">A</span> <span class="o">*</span> <span class="n">SigmoidParameter</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">c</span><span class="p">))</span></div>


    <span class="c1"># pylint: enable=arguments-differ</span>

<div class="viewcode-block" id="SigmoidGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">par_string</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* (</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">A</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">par_string</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="LogSigmoidGrowth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowth">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogSigmoidGrowth</span><span class="p">(</span><span class="n">LogSigmoidParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-scale sigmoid growth model transformation.</span>

<span class="sd">    Implements the logarithm of sigmoid growth: log(x) = log_A + log_sigmoid(r*(t - c))</span>
<span class="sd">    This provides numerical stability and ensures positive values.</span>

<span class="sd">    :param t: Time parameter</span>
<span class="sd">    :type t: custom_types.CombinableParameterType</span>
<span class="sd">    :param log_A: Log-amplitude parameter (log of carrying capacity)</span>
<span class="sd">    :type log_A: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param c: Inflection point parameter</span>
<span class="sd">    :type c: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    :cvar LOWER_BOUND: No lower bound (None)</span>
<span class="sd">    :cvar UPPER_BOUND: No upper bound (None)</span>

<span class="sd">    This parameterization is ideal for:</span>
<span class="sd">    - Extreme parameter regimes</span>
<span class="sd">    - Log-scale statistical modeling</span>
<span class="sd">    - When initial conditions are naturally in log-space</span>
<span class="sd">    - Maximum numerical precision requirements</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; time_points = Constant(np.linspace(0, 10, 100))</span>
<span class="sd">        &gt;&gt;&gt; log_carrying_capacity = Normal(mu=6.9, sigma=0.1)  # log(1000)</span>
<span class="sd">        &gt;&gt;&gt; growth_rate = Normal(mu=1.0, sigma=0.1)</span>
<span class="sd">        &gt;&gt;&gt; inflection_time = Normal(mu=5.0, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; log_population = LogSigmoidGrowth(t=time_points, log_A=log_carrying_capacity,</span>
<span class="sd">        &gt;&gt;&gt;                                     r=growth_rate, c=inflection_time)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize log-sigmoid growth model.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param log_A: Log-amplitude parameter</span>
<span class="sd">        :param r: Rate parameter</span>
<span class="sd">        :param c: Inflection point parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnaryTransformedParameter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">log_A</span><span class="o">=</span><span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">log_A</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="LogSigmoidGrowth.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowth.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">log_A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-sigmoid growth: log_A + log_sigmoid(r * (t - c)).</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param log_A: Log-amplitude values</span>
<span class="sd">        :param r: Rate values</span>
<span class="sd">        :param c: Inflection point values</span>

<span class="sd">        :returns: Log-sigmoid growth values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">log_A</span> <span class="o">+</span> <span class="n">LogSigmoidParameter</span><span class="o">.</span><span class="n">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">c</span><span class="p">))</span></div>


    <span class="c1"># pylint: enable=arguments-differ</span>

<div class="viewcode-block" id="LogSigmoidGrowth.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowth.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_A</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">par_string</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* (</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">log_A</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">par_string</span><span class="si">}</span><span class="s2">&quot;</span></div>
</div>



<div class="viewcode-block" id="SigmoidGrowthInitParametrization">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowthInitParametrization">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SigmoidGrowthInitParametrization</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sigmoid growth with initial value parameterization.</span>

<span class="sd">    Alternative parameterization of sigmoid growth in terms of initial abundances</span>
<span class="sd">    rather than carrying capacity. Uses numerically stable log-add-exp computation.</span>

<span class="sd">    :param t: Time parameter</span>
<span class="sd">    :type t: custom_types.CombinableParameterType</span>
<span class="sd">    :param x0: Initial abundance parameter</span>
<span class="sd">    :type x0: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param c: Offset parameter (related to carrying capacity)</span>
<span class="sd">    :type c: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    :cvar LOWER_BOUND: Values are bounded below by 0.0</span>
<span class="sd">    :cvar UPPER_BOUND: No upper bound (None)</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Parameterizes sigmoid growth by initial value x0</span>
<span class="sd">    - Uses log-add-exp trick for numerical stability</span>
<span class="sd">    - Avoids direct computation of large exponentials</span>
<span class="sd">    - Maintains sigmoid growth dynamics</span>

<span class="sd">    This parameterization is useful when:</span>
<span class="sd">    - Initial conditions are better known than carrying capacity</span>
<span class="sd">    - Numerical stability is crucial</span>
<span class="sd">    - Working with extreme parameter values</span>
<span class="sd">    - Modeling relative growth from baseline</span>

<span class="sd">    The transformation uses the identity:</span>
<span class="sd">    x(t) = x0 * exp(log(1+exp(r*c)) - log(1+exp(r*(c-t))))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="s2">&quot;custom_types.Float&quot;</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">x0</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize sigmoid growth with initial value parameterization.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param x0: Initial abundance parameter</span>
<span class="sd">        :param r: Growth rate parameter</span>
<span class="sd">        :param c: Offset parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-renamed, arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">x0</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="SigmoidGrowthInitParametrization.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowthInitParametrization.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute sigmoid growth with initial parameterization using log-add-exp.</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param x0: Initial abundance values</span>
<span class="sd">        :param r: Rate values</span>
<span class="sd">        :param c: Offset values</span>

<span class="sd">        :returns: Sigmoid growth values</span>

<span class="sd">        Uses log-add-exp for numerical stability in computing:</span>
<span class="sd">        x0 * exp(log(1+exp(r*c)) - log(1+exp(r*(c-t))))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the module</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

        <span class="c1"># Get the fold-change. We use the log-add-exp function to calculate this</span>
        <span class="c1"># in a more numerically stable way</span>
        <span class="n">zero</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">np</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x0</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">foldchange</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
            <span class="n">mod</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span> <span class="o">-</span> <span class="n">mod</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="c1"># Calculate the abundance</span>
        <span class="k">return</span> <span class="n">x0</span> <span class="o">*</span> <span class="n">foldchange</span></div>


<div class="viewcode-block" id="SigmoidGrowthInitParametrization.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.SigmoidGrowthInitParametrization.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">x0</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># pylint: disable=invalid-name</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate using Stan&#39;s log1p_exp function.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">x0</span><span class="si">}</span><span class="s2"> .* exp(log1p_exp(</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">) - log1p_exp(</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* (</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">)))&quot;</span></div>
</div>


    <span class="c1"># pylint: enable=arguments-renamed, arguments-differ</span>


<div class="viewcode-block" id="LogSigmoidGrowthInitParametrization">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowthInitParametrization">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogSigmoidGrowthInitParametrization</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-scale sigmoid growth with initial value parameterization.</span>

<span class="sd">    Log-space version of sigmoid growth parameterized by initial values,</span>
<span class="sd">    providing numerical stability and guaranteed positive outputs.</span>

<span class="sd">    :param t: Time parameter</span>
<span class="sd">    :type t: custom_types.CombinableParameterType</span>
<span class="sd">    :param log_x0: Log of initial abundance parameter</span>
<span class="sd">    :type log_x0: custom_types.CombinableParameterType</span>
<span class="sd">    :param r: Growth rate parameter</span>
<span class="sd">    :type r: custom_types.CombinableParameterType</span>
<span class="sd">    :param c: Offset parameter</span>
<span class="sd">    :type c: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    :cvar LOWER_BOUND: No lower bound (None)</span>
<span class="sd">    :cvar UPPER_BOUND: No upper bound (None)</span>

<span class="sd">    Mathematical Properties:</span>
<span class="sd">    - Fully operates in log-space for numerical stability</span>
<span class="sd">    - Parameterized by log of initial conditions</span>
<span class="sd">    - Uses log-add-exp computations throughout</span>
<span class="sd">    - Maintains sigmoid growth dynamics</span>

<span class="sd">    This parameterization is ideal for:</span>
<span class="sd">    - Extreme parameter regimes</span>
<span class="sd">    - Log-scale statistical modeling</span>
<span class="sd">    - When initial conditions are naturally in log-space</span>
<span class="sd">    - Maximum numerical precision requirements</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; time_points = Constant(np.linspace(0, 10, 100))</span>
<span class="sd">        &gt;&gt;&gt; log_initial = Normal(mu=4.6, sigma=0.1)  # log(100)</span>
<span class="sd">        &gt;&gt;&gt; growth_rate = Normal(mu=1.0, sigma=0.1)</span>
<span class="sd">        &gt;&gt;&gt; offset = Normal(mu=5.0, sigma=0.5)</span>
<span class="sd">        &gt;&gt;&gt; log_abundance = LogSigmoidGrowthInitParametrization(t=time_points,</span>
<span class="sd">        &gt;&gt;&gt;                 log_x0=log_initial, r=growth_rate, c=offset)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LOWER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">UPPER_BOUND</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">log_x0</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize log-sigmoid growth with initial value parameterization.</span>

<span class="sd">        :param t: Time parameter</span>
<span class="sd">        :param log_x0: Log of initial abundance parameter</span>
<span class="sd">        :param r: Growth rate parameter</span>
<span class="sd">        :param c: Offset parameter</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">log_x0</span><span class="o">=</span><span class="n">log_x0</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># pylint: disable=arguments-renamed, arguments-differ</span>
    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">log_x0</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">t</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">log_x0</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">r</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="s2">&quot;custom_types.SampleType&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span> <span class="o">...</span>

<div class="viewcode-block" id="LogSigmoidGrowthInitParametrization.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowthInitParametrization.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">log_x0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute log-sigmoid growth with initial parameterization.</span>

<span class="sd">        :param t: Time values</span>
<span class="sd">        :param log_x0: Log initial abundance values</span>
<span class="sd">        :param r: Rate values</span>
<span class="sd">        :param c: Offset values</span>

<span class="sd">        :returns: Log-sigmoid growth values</span>

<span class="sd">        Computes: log_x0 + log(1+exp(r*c)) - log(1+exp(r*(c-t)))</span>
<span class="sd">        using numerically stable log-add-exp operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the module</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">log_x0</span><span class="p">)</span>

        <span class="c1"># Define zero</span>
        <span class="n">zero</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">np</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">log_x0</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Calculate</span>
        <span class="k">return</span> <span class="n">log_x0</span> <span class="o">+</span> <span class="n">mod</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span> <span class="o">-</span> <span class="n">mod</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span></div>


<div class="viewcode-block" id="LogSigmoidGrowthInitParametrization.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.LogSigmoidGrowthInitParametrization.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_x0</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># pylint: disable=invalid-name</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate using Stan&#39;s log1p_exp function.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">log_x0</span><span class="si">}</span><span class="s2"> + log1p_exp(</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">) - log1p_exp(</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> .* (</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">))&quot;</span></div>
</div>



<div class="viewcode-block" id="ConvolveSequence">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ConvolveSequence</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sequence convolution transformation using weight matrices.</span>

<span class="sd">    Performs convolution operation on ordinally-encoded sequences using provided</span>
<span class="sd">    weight matrices. This is commonly used for sequence modeling and pattern</span>
<span class="sd">    recognition in biological sequences or text data.</span>

<span class="sd">    :param weights: Weight matrix for convolution (at least 2D)</span>
<span class="sd">    :type weights: custom_types.CombinableParameterType</span>
<span class="sd">    :param ordinals: Ordinally-encoded sequence array (at least 1D)</span>
<span class="sd">    :type ordinals: custom_types.CombinableParameterType</span>
<span class="sd">    :param kwargs: Additional arguments passed to parent class</span>

<span class="sd">    :cvar SHAPE_CHECK: Disabled for complex shape operations (False)</span>
<span class="sd">    :cvar FORCE_LOOP_RESET: Forces loop reset in Stan code (True)</span>
<span class="sd">    :cvar FORCE_PARENT_NAME: Forces parent naming in Stan code (True)</span>

<span class="sd">    Shape Requirements:</span>
<span class="sd">    - Weights: (..., kernel_size, alphabet_size)</span>
<span class="sd">    - Ordinals: (..., sequence_length)</span>
<span class="sd">    - Output: (..., sequence_length - kernel_size + 1)</span>

<span class="sd">    The transformation applies convolution by:</span>
<span class="sd">    1. Sliding a kernel of size kernel_size over the sequence</span>
<span class="sd">    2. Using ordinal values to index into the weight matrix</span>
<span class="sd">    3. Summing weighted values for each position</span>

<span class="sd">    This is commonly used for:</span>
<span class="sd">    - DNA/RNA sequence analysis</span>
<span class="sd">    - Protein sequence modeling</span>
<span class="sd">    - Text processing with character-level models</span>
<span class="sd">    - Pattern recognition in discrete sequences</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; # DNA sequence convolution</span>
<span class="sd">        &gt;&gt;&gt; weights = Normal(mu=0, sigma=1, shape=(motif_length, 4))  # 4 nucleotides</span>
<span class="sd">        &gt;&gt;&gt; dna_sequence = Constant(encoded_dna)  # 0,1,2,3 for A,C,G,T</span>
<span class="sd">        &gt;&gt;&gt; motif_scores = ConvolveSequence(weights=weights, ordinals=dna_sequence)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SHAPE_CHECK</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">FORCE_LOOP_RESET</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">FORCE_PARENT_NAME</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="n">ordinals</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize sequence convolution with shape validation.</span>

<span class="sd">        :param weights: Weight matrix (kernel_size × alphabet_size in last 2 dims)</span>
<span class="sd">        :param ordinals: Ordinal sequence array</span>
<span class="sd">        :param kwargs: Additional arguments</span>

<span class="sd">        :raises ValueError: If weights is not at least 2D</span>
<span class="sd">        :raises ValueError: If ordinals is not at least 1D</span>
<span class="sd">        :raises ValueError: If shapes are incompatible for broadcasting</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Weights must be at least 2D.</span>
        <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Weights must be at least a 2D parameter.&quot;</span><span class="p">)</span>

        <span class="c1"># Sequence must be at least 1D</span>
        <span class="k">if</span> <span class="n">ordinals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sequence must be at least a 1D parameter.&quot;</span><span class="p">)</span>

        <span class="c1"># Note features of the weights. This is the last two dimensions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphabet_size</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>

        <span class="c1"># The first N - 2 dimensions of the weights must align with the first</span>
        <span class="c1"># N - 1 dimensions of the ordinals</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Incompatible shapes between weights and ordinals. The shapes must &quot;</span>
                <span class="s2">&quot;be broadcastable in the batch dimensions (all but last two for &quot;</span>
                <span class="s2">&quot;the weights and all but the last for the ordinals). Got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;weights: </span><span class="si">{</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, ordinals: </span><span class="si">{</span><span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>

        <span class="c1"># The final dimension has the size of the sequence length adjusted by the</span>
        <span class="c1"># convolution</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,)</span>

        <span class="c1"># Init using inherited method.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">ordinals</span><span class="o">=</span><span class="n">ordinals</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="ConvolveSequence.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">ordinals</span><span class="p">):</span>  <span class="c1"># pylint: disable=arguments-differ</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Performs the convolution&quot;&quot;&quot;</span>

        <span class="c1"># If numpy, loop over the leading dimension</span>
        <span class="k">assert</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Decide on the module for the operation</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># Determine the number of dimensions to prepend to each array</span>
        <span class="n">weights_n_prepends</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">ordinal_n_prepends</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Get the padded shapes. This is just aligning the shapes for broadcasting.</span>
        <span class="n">padded_weights_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">*</span> <span class="n">weights_n_prepends</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">padded_ordinals_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">*</span> <span class="n">ordinal_n_prepends</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordinals</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">padded_weights_shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">padded_ordinals_shape</span><span class="p">)</span>

        <span class="c1"># Set output array and build a set of filter indices</span>
        <span class="n">output_arr</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">filter_indices</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">)</span>

        <span class="c1"># If torch, send arrays to appropriate device</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="n">torch</span><span class="p">:</span>
            <span class="n">filter_indices</span> <span class="o">=</span> <span class="n">filter_indices</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output_arr</span> <span class="o">=</span> <span class="n">output_arr</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Loop over the different weights</span>
        <span class="k">for</span> <span class="n">weights_inds</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">ndindex</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]):</span>

            <span class="c1"># Prepend `None` to the weight indices if needed</span>
            <span class="n">weights_inds</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">*</span> <span class="n">weights_n_prepends</span> <span class="o">+</span> <span class="n">weights_inds</span>

            <span class="c1"># Determine the ordinal and output indices. If weights or ordinals</span>
            <span class="c1"># are a singleton, slice all for the ordinal indices.</span>
            <span class="n">ordinal_inds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">output_inds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="p">(</span><span class="n">weight_dim_size</span><span class="p">,</span> <span class="n">ord_dim_size</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">padded_weights_shape</span><span class="p">,</span> <span class="n">padded_ordinals_shape</span><span class="p">)</span>
            <span class="p">):</span>

                <span class="c1"># We can never have both weight and ord dim sizes be `None`</span>
                <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">weight_dim_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ord_dim_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>

                <span class="c1"># If the ordinal dimension is `None`, then the output dimension is whatever</span>
                <span class="c1"># the weight dimension is. We do not record an ordinal index.</span>
                <span class="n">weight_ind</span> <span class="o">=</span> <span class="n">weights_inds</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">ord_dim_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">output_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_ind</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="c1"># If the weight dimension is a singleton we slice all for the ordinal and</span>
                <span class="c1"># the output</span>
                <span class="k">if</span> <span class="n">weight_dim_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">weight_dim_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">ordinal_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
                    <span class="n">output_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>

                <span class="c1"># If the ordinal dimension is a singleton, add &quot;0&quot; to the indices for the</span>
                <span class="c1"># ordinals and the weights ind for the output</span>
                <span class="k">elif</span> <span class="n">ord_dim_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">ordinal_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">output_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_ind</span><span class="p">)</span>

                <span class="c1"># Otherwise, identical index to the weights for both</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ordinal_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_ind</span><span class="p">)</span>
                    <span class="n">output_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_ind</span><span class="p">)</span>

            <span class="c1"># Convert indices to tuples</span>
            <span class="n">ordinal_inds</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">ordinal_inds</span><span class="p">)</span>
            <span class="n">output_inds</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output_inds</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_inds</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="c1"># Get the matrix and set of sequences to which it will be applied</span>
            <span class="n">weights_matrix</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weights_inds</span><span class="p">]</span>
            <span class="n">ordinal_matrix</span> <span class="o">=</span> <span class="n">ordinals</span><span class="p">[</span><span class="n">ordinal_inds</span><span class="p">]</span>
            <span class="k">assert</span> <span class="n">weights_matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>

            <span class="c1"># Run convolution for this batch by sliding over the sequence length</span>
            <span class="k">for</span> <span class="n">convind</span><span class="p">,</span> <span class="n">upper_slice</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">ordinal_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">):</span>

                <span class="c1"># Get the lower bound</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">upper_slice</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span>

                <span class="c1"># Slice the sequence and pull the appropriate weights. Sum the weights.</span>
                <span class="n">output_arr</span><span class="p">[</span><span class="n">output_inds</span> <span class="o">+</span> <span class="p">(</span><span class="n">convind</span><span class="p">,)]</span> <span class="o">=</span> <span class="n">weights_matrix</span><span class="p">[</span>
                    <span class="n">filter_indices</span><span class="p">,</span> <span class="n">ordinal_matrix</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">lower</span><span class="p">:</span><span class="n">upper_slice</span><span class="p">]</span>
                <span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s2">&quot;dim&quot;</span> <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="n">torch</span> <span class="k">else</span> <span class="s2">&quot;axis&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span>

        <span class="c1"># No Nan&#39;s in output</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">module</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">output_arr</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">output_arr</span></div>


<div class="viewcode-block" id="ConvolveSequence.get_index_offset">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence.get_index_offset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_index_offset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;abstract_model_component.AbstractModelComponent&quot;</span><span class="p">],</span>
        <span class="n">offset_adjustment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate index offset with special handling for weights.</span>

<span class="sd">        :param query: Component or parameter name to query</span>
<span class="sd">        :param offset_adjustment: Base offset adjustment</span>

<span class="sd">        :returns: Index offset (adjusted +1 for weights parameter)</span>
<span class="sd">        :rtype: int</span>

<span class="sd">        The weights parameter requires special offset handling because</span>
<span class="sd">        its last two dimensions are used directly in the convolution</span>
<span class="sd">        rather than being broadcast.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run the inherited method</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_index_offset</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">offset_adjustment</span><span class="p">)</span>

        <span class="c1"># Adjust if needed</span>
        <span class="k">if</span> <span class="n">query</span> <span class="o">==</span> <span class="s2">&quot;weights&quot;</span> <span class="ow">or</span> <span class="n">query</span> <span class="ow">is</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">offset</span></div>


<div class="viewcode-block" id="ConvolveSequence.get_right_side">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence.get_right_side">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_right_side</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index_opts</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">start_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">end_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offset_adjustment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate right-side code with proper dimension handling.</span>

<span class="sd">        Sets default end_dims to exclude the last weight dimension (-2),</span>
<span class="sd">        ensuring both kernel_size and alphabet_size dimensions are preserved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">end_dims</span> <span class="o">=</span> <span class="n">end_dims</span> <span class="ow">or</span> <span class="p">{</span><span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">}</span>

        <span class="c1"># Run the AbstractModelParameter version of the method to get each model</span>
        <span class="c1"># component formatted appropriately. Note that we ignore the last dimension</span>
        <span class="c1"># of the weights. This is because we need both dimensions in the Stan code.</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_right_side</span><span class="p">(</span>
            <span class="n">index_opts</span><span class="p">,</span> <span class="n">end_dims</span><span class="o">=</span><span class="n">end_dims</span><span class="p">,</span> <span class="n">offset_adjustment</span><span class="o">=</span><span class="n">offset_adjustment</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ConvolveSequence.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ordinals</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan convolution function call.</span>

<span class="sd">        :param weights: Formatted weights parameter name</span>
<span class="sd">        :type weights: str</span>
<span class="sd">        :param ordinals: Formatted ordinals parameter name</span>
<span class="sd">        :type ordinals: str</span>

<span class="sd">        :returns: Stan function call for sequence convolution</span>
<span class="sd">        :rtype: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This runs a custom function</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;convolve_sequence(</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ordinals</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="ConvolveSequence.get_supporting_functions">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.ConvolveSequence.get_supporting_functions">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_supporting_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return required Stan function includes.</span>

<span class="sd">        :returns: List including pssm.stanfunctions for convolution support</span>
<span class="sd">        :rtype: list[str]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_supporting_functions</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;#include pssm.stanfunctions&quot;</span><span class="p">]</span></div>
</div>



<div class="viewcode-block" id="IndexParameter">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">IndexParameter</span><span class="p">(</span><span class="n">TransformedParameter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Array indexing transformation with NumPy-compatible semantics.</span>

<span class="sd">    Creates indexed subsets of parameters using slicing, scalar indexing,</span>
<span class="sd">    and array indexing. Follows NumPy indexing conventions rather than</span>
<span class="sd">    Stan conventions for consistency with Python data manipulation.</span>

<span class="sd">    :param dist: Parameter to index</span>
<span class="sd">    :type dist: custom_types.CombinableParameterType</span>
<span class="sd">    :param indices: Indexing specifications (slices, integers, arrays)</span>
<span class="sd">    :type indices: custom_types.IndexType</span>

<span class="sd">    :cvar SHAPE_CHECK: Disabled for complex indexing operations (False)</span>
<span class="sd">    :cvar FORCE_PARENT_NAME: Forces parent naming in Stan code (True)</span>

<span class="sd">    Supported Index Types:</span>
<span class="sd">    - **slice**: Standard Python slicing with start:stop (step=1 only)</span>
<span class="sd">    - **int**: Single element selection</span>
<span class="sd">    - **np.ndarray**: Advanced indexing with integer arrays. 1D only. Follows numpy convention.</span>
<span class="sd">    - **Ellipsis**: Automatic dimension filling</span>
<span class="sd">    - **None**: New axis insertion</span>

<span class="sd">    Important Differences from Stan:</span>
<span class="sd">    - Uses 0-based indexing (Python convention)</span>
<span class="sd">    - Advanced indexing follows NumPy broadcasting rules</span>
<span class="sd">    - Negative indices are supported and converted appropriately</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; data = Normal(mu=0, sigma=1, shape=(10, 5))</span>
<span class="sd">        &gt;&gt;&gt; # Slice first 5 rows</span>
<span class="sd">        &gt;&gt;&gt; subset = IndexParameter(data, slice(0, 5))</span>
<span class="sd">        &gt;&gt;&gt; # Select specific elements</span>
<span class="sd">        &gt;&gt;&gt; selected = IndexParameter(data, [0, 2, 4], [1, 3, 0])  # NumPy-style</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SHAPE_CHECK</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">FORCE_PARENT_NAME</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dist</span><span class="p">:</span> <span class="s2">&quot;custom_types.CombinableParameterType&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="n">indices</span><span class="p">:</span> <span class="s2">&quot;custom_types.IndexType&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize indexing transformation.</span>

<span class="sd">        :param dist: Parameter to index</span>
<span class="sd">        :param indices: Indexing specifications</span>

<span class="sd">        The initialization processes all index types, converts negative</span>
<span class="sd">        indices to positive, validates array dimensions, and creates</span>
<span class="sd">        appropriate constant parameters for array indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We need the shape of what we&#39;re indexing to prep for parent init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># We need the input indices for torch and numpy operations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_python_indices</span> <span class="o">=</span> <span class="n">indices</span>

        <span class="c1"># Process and unify the different index types</span>
        <span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stan_indices</span><span class="p">,</span> <span class="n">parents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="c1"># Init using parent method. Provide the shape with `None` values removed --</span>
        <span class="c1"># these are the dimensions that are removed by indexing</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">parents</span><span class="p">)</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">neg_to_pos</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">neg_ind</span><span class="p">:</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="s2">&quot;custom_types.Integer&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">:</span> <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">neg_to_pos</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">neg_ind</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">],</span> <span class="n">dim</span><span class="p">:</span> <span class="s2">&quot;custom_types.Integer&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">]:</span> <span class="o">...</span>

<div class="viewcode-block" id="IndexParameter.neg_to_pos">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.neg_to_pos">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">neg_to_pos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neg_ind</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert negative indices to positive indices.</span>

<span class="sd">        :param neg_ind: Negative index or array of indices</span>
<span class="sd">        :param dim: Dimension size for conversion</span>

<span class="sd">        :returns: Positive indices</span>

<span class="sd">        :raises ValueError: If indices are out of bounds</span>

<span class="sd">        Handles both scalar and array indices, performing bounds checking</span>
<span class="sd">        and conversion from Python&#39;s negative indexing convention.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If a numpy array, we update negative positions only</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">neg_ind</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">neg_ind</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">out</span><span class="p">[</span><span class="n">out</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

            <span class="c1"># There should be no negatives</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">out</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Negative indices </span><span class="si">{</span><span class="n">neg_ind</span><span class="si">}</span><span class="s2"> cannot be converted to positive &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;indices for dimension </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># The max should be less than the dimension size</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">out</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Indices </span><span class="si">{</span><span class="n">neg_ind</span><span class="si">}</span><span class="s2"> exceed the size of dimension </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;with shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="k">return</span> <span class="n">out</span>

        <span class="c1"># If a single integer, we convert it directly.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">neg_ind</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">neg_ind</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">if</span> <span class="n">neg_ind</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">neg_ind</span>

            <span class="c1"># Check that the index is within bounds</span>
            <span class="k">if</span> <span class="n">out</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Negative index </span><span class="si">{</span><span class="n">neg_ind</span><span class="si">}</span><span class="s2"> cannot be converted to positive &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;index for dimension </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">out</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Index </span><span class="si">{</span><span class="n">neg_ind</span><span class="si">}</span><span class="s2"> exceeds the size of dimension </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;with shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="k">return</span> <span class="n">out</span>

        <span class="c1"># Error if the type is not supported</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unsupported index type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">neg_ind</span><span class="p">)</span><span class="si">}</span><span class="s2">. Expected int or numpy array.&quot;</span>
        <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_process_indices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="s2">&quot;custom_types.IndexType&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="s2">&quot;custom_types.IndexType&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">constants</span><span class="o">.</span><span class="n">Constant</span><span class="p">],</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process and validate all indexing specifications.</span>

<span class="sd">        :param indices: Raw indexing specifications</span>

<span class="sd">        :returns: Tuple of (output_shape, processed_indices, constant_parents)</span>

<span class="sd">        This method handles the complex logic of:</span>
<span class="sd">        - Processing different index types (slices, integers, arrays, ellipsis)</span>
<span class="sd">        - Calculating output shapes</span>
<span class="sd">        - Converting to Stan-compatible 1-based indexing</span>
<span class="sd">        - Creating constant parameters for array indices</span>
<span class="sd">        - Validating consistency across multiple array indices</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">process_ellipsis</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Helper function to process Ellipses&quot;&quot;&quot;</span>
            <span class="c1"># We can only have one ellipsis</span>
            <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">indices</span> <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="bp">Ellipsis</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one ellipsis is allowed in indexing.&quot;</span><span class="p">)</span>

            <span class="c1"># Add slices to the processed dimensions</span>
            <span class="n">n_real_dims</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="mi">1</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">indices</span> <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">Ellipsis</span> <span class="ow">and</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="n">n_to_add</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_real_dims</span>
            <span class="n">processed_inds</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_to_add</span><span class="p">)])</span>

            <span class="c1"># The shape is extended by the number added</span>
            <span class="n">shape</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">shape_ind</span> <span class="p">:</span> <span class="n">shape_ind</span> <span class="o">+</span> <span class="n">n_to_add</span><span class="p">])</span>

            <span class="c1"># Return the number of added dimensions</span>
            <span class="k">return</span> <span class="n">n_to_add</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">process_slice</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Helper function to process slices.&quot;&quot;&quot;</span>
            <span class="c1"># Step cannot be set</span>
            <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">step</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Step size </span><span class="si">{</span><span class="n">ind</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2"> is not supported in IndexParameter transformation.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Get the size of the output shape (stop - start after converting negatives</span>
            <span class="c1"># to positives)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_to_pos</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">shape_ind</span><span class="p">)</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dist_shape</span><span class="p">[</span><span class="n">shape_ind</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_to_pos</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="n">shape_ind</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Update outputs. Note that processed outputs are a new slice and that</span>
            <span class="c1"># we do not add 1 to stop because Stan slices are inclusive while Python</span>
            <span class="c1"># are exclusive</span>
            <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
            <span class="n">processed_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="p">))</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">process_array</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Helper function to process numpy arrays and constants.&quot;&quot;&quot;</span>

            <span class="c1"># Must be a 1D array</span>
            <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot index with numpy array with more than 1 dimension&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">ind</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s2">&quot;Should not get here&quot;</span><span class="p">)</span>

            <span class="c1"># Ensure the array contains integers</span>
            <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Indexing with non-integer arrays is not supported. Got dtype &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ind</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Must be the same as previous 1-d arrays</span>
            <span class="n">arrlen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">int_arr_len</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">int_arr_len</span> <span class="o">!=</span> <span class="n">arrlen</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;All 1-dimensional integer arrays must have the same length. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got lengths </span><span class="si">{</span><span class="n">int_arr_len</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">arrlen</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Build a constant for the index. This involves adjusting the indices</span>
            <span class="c1"># to be Stan-compatible (1-indexed, no negative indices).</span>
            <span class="n">constant_arr</span> <span class="o">=</span> <span class="n">constants</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">neg_to_pos</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">shape_ind</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">togglable</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

            <span class="c1"># Record</span>
            <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arrlen</span><span class="p">)</span>
            <span class="n">parents</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;idx_</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">constant_arr</span>
            <span class="n">processed_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">constant_arr</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">arrlen</span>

        <span class="c1"># Set up for recording</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># This parameter&#39;s shape</span>
        <span class="n">processed_inds</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Indices processed for use in Stan</span>
        <span class="n">shape_ind</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Current dimension in the indexed parameter</span>
        <span class="n">parents</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">constants</span><span class="o">.</span><span class="n">Constant</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Constants for arrays</span>
        <span class="n">int_arr_len</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Length of integer arrays</span>

        <span class="c1"># Process indices</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>

            <span class="c1"># Process ellipses</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="bp">Ellipsis</span><span class="p">:</span>
                <span class="n">shape_ind</span> <span class="o">+=</span> <span class="n">process_ellipsis</span><span class="p">()</span>

            <span class="c1"># Process slices</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
                <span class="n">process_slice</span><span class="p">()</span>
                <span class="n">shape_ind</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Numpy arrays are also processed by their own function</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">int_arr_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">int_arr_len</span><span class="p">,</span> <span class="n">process_array</span><span class="p">())</span>
                <span class="n">shape_ind</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Integers must be made positive</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">processed_inds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neg_to_pos</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">shape_ind</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">shape_ind</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># `None` values add a new dimension to the output.</span>
            <span class="k">elif</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Nothing else is legal</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Indexing supported by slicing, numpy arrays, and integers only.&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Remove None values from the shape</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">processed_inds</span><span class="p">),</span> <span class="n">parents</span>

    <span class="c1"># Note that parents are ignored here as their indices have been adjusted to</span>
    <span class="c1"># reflect Stan&#39;s 1-indexing and no negative indices. We use the Python indices</span>
    <span class="c1"># stored earlier as a result. The parents kwargs is included for compatibility</span>
<div class="viewcode-block" id="IndexParameter.run_np_torch_op">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.run_np_torch_op">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_np_torch_op</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ, unused-argument</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="o">**</span><span class="n">parents</span>
    <span class="p">):</span>
        <span class="c1"># If torch, numpy arrays must go to torch</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">choose_module</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="n">torch</span><span class="p">:</span>
            <span class="n">inds</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
                    <span class="k">else</span> <span class="n">ind</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_indices</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_indices</span>

        <span class="c1"># Index and check shape</span>
        <span class="n">indexed</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">indexed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">return</span> <span class="n">indexed</span></div>


<div class="viewcode-block" id="IndexParameter.get_right_side">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.get_right_side">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_right_side</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index_opts</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">start_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">end_dims</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offset_adjustment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate Stan indexing code.</span>

<span class="sd">        :returns: Stan indexing expression</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Gets the name of the variable that is being indexed, then passes it to</span>
<span class="sd">        the `write_stan_operation` method to get the full Stan code for the transformation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_stan_operation</span><span class="p">(</span><span class="n">dist</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">model_varname</span><span class="p">)</span></div>


<div class="viewcode-block" id="IndexParameter.write_stan_operation">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.write_stan_operation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">write_stan_operation</span><span class="p">(</span>  <span class="c1"># pylint: disable=arguments-differ</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dist</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate complete Stan indexing expression.</span>

<span class="sd">        :param dist: Variable name to index</span>
<span class="sd">        :type dist: str</span>

<span class="sd">        :returns: Stan indexing expression with bracket notation</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Handles complex indexing patterns including:</span>
<span class="sd">        - Multiple array indices (creates separate bracket groups)</span>
<span class="sd">        - Mixed slicing and array indexing</span>
<span class="sd">        - Proper 1-based index conversion for Stan</span>
<span class="sd">        - Colon notation for full dimension slicing</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compile all indices. Every time we encounter an array index, we start</span>
        <span class="c1"># a new indexing operation. This allows us to mimic numpy behavior in Stan.</span>
        <span class="n">components</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_component</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">index_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">array_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stan_indices</span><span class="p">:</span>

            <span class="c1"># Handle slices</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
                <span class="n">start</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">start</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">start</span><span class="p">)</span>
                <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">stop</span><span class="p">)</span>
                <span class="n">index_pos</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># We keep a dimension with this operation</span>
                <span class="n">current_component</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">end</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Handle integers</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">current_component</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>

            <span class="c1"># If an array, we need to use the constant that we defined</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span> <span class="n">constants</span><span class="o">.</span><span class="n">Constant</span><span class="p">):</span>

                <span class="c1"># Must be a 1D array</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">ind</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>

                <span class="c1"># If we have already encountered an array, start a new component,</span>
                <span class="c1"># padding out the current component with colons.</span>
                <span class="k">if</span> <span class="n">array_counter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_component</span><span class="p">)</span>
                    <span class="n">current_component</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;:&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">index_pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Record the array as a component</span>
                <span class="n">current_component</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_parents</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;idx_</span><span class="si">{</span><span class="n">array_counter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_indexed_varname</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="p">)</span>

                <span class="c1"># Update counters</span>
                <span class="n">index_pos</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># We keep a dimension with this operation</span>
                <span class="n">array_counter</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># Note finding another array</span>

            <span class="c1"># Error with anything else</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported index type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Record the last component</span>
        <span class="n">components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_component</span><span class="p">)</span>

        <span class="c1"># Join all components</span>
        <span class="k">return</span> <span class="n">dist</span> <span class="o">+</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="s2">&quot;][&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">components</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span></div>


<div class="viewcode-block" id="IndexParameter.get_transformation_assignment">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.get_transformation_assignment">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_transformation_assignment</span><span class="p">(</span>  <span class="c1"># pylint: disable=unused-argument</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">index_opts</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate transformation assignment without index options.</span>

<span class="sd">        :param index_opts: Index options (ignored for direct assignment)</span>

<span class="sd">        :returns: Stan assignment statement</span>
<span class="sd">        :rtype: str</span>

<span class="sd">        Indexing parameters are assigned directly without loop indexing</span>
<span class="sd">        since they represent specific element selection rather than</span>
<span class="sd">        computed transformations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=no-value-for-parameter</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_transformation_assignment</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># Assigned directly</span></div>


    <span class="c1"># The definition depth is always 0 for this transformation</span>
<div class="viewcode-block" id="IndexParameter.get_assign_depth">
<a class="viewcode-back" href="../../../../../docs/api/model/components/transformations/transformed_parameters.html#scistanpy.model.components.transformations.transformed_parameters.IndexParameter.get_assign_depth">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_assign_depth</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;custom_types.Integer&quot;</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0116</span>
        <span class="k">return</span> <span class="mi">0</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">force_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Force explicit naming for indexed parameters.</span>

<span class="sd">        :returns: Always True</span>
<span class="sd">        :rtype: bool</span>

<span class="sd">        Indexed parameters must be explicitly named in Stan code to</span>
<span class="sd">        enable proper variable reference and assignment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../index.html">SciStanPy</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../docs/api/index.html">SciStanPy API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../../index.html">Module code</a><ul>
  <li><a href="../../../../scistanpy.html">scistanpy</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Bruce Wittmann.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.3.0</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>