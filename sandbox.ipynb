{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import dms_stan.model.components.parameters\n",
    "# import dms_stan.operations as dms_ops\n",
    "\n",
    "# from dms_stan.flip_dsets import load_nuclease_data, MultiNucDatasetType\n",
    "# from dms_stan.model import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[abc.NormalCDF,\n",
       " dms_stan.model.components.cdf.CDF,\n",
       " dms_stan.model.components.cdf.CDFLike,\n",
       " dms_stan.model.components.transformed_parameters.TransformedParameter,\n",
       " dms_stan.model.components.transformed_parameters.Transformation,\n",
       " dms_stan.model.components.abstract_model_component.AbstractModelComponent,\n",
       " abc.ABC,\n",
       " dms_stan.model.components.transformed_parameters.TransformableParameter,\n",
       " object]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dms_components.Normal.CDF.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_type = typing.get_type_hints(dms_components.Normal.__init__)[\"mu\"]\n",
    "typing.get_origin(mu_type)\n",
    "set(typing.get_args(mu_type)).issubset(typing.get_args(dms.custom_types.CombinableParameterType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_type is dms.custom_types.ContinuousParameterType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Union[dms_stan.model.components.transformed_parameters.TransformedParameter, dms_stan.model.components.constants.Constant, dms_stan.model.components.parameters.ContinuousDistribution, float, numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.floating]], dms_stan.model.components.parameters.DiscreteDistribution, int, numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.integer]]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dms.custom_types.CombinableParameterType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (861022897.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# def check_param_type(annotation: str | type, target: type) -> bool:\n",
    "#     \"\"\"Check if the annotation is a subclass of the target type.\"\"\"\n",
    "#     # If the annotation is a string, it might be a forward reference\n",
    "#     if isinstance(annotation, str):\n",
    "\n",
    "import dms_stan as dms\n",
    "from\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "# Get the type annotation for 'mu'\n",
    "mu_type = typing.get_type_hints(dms_components.Normal.__init__)[\"mu\"]\n",
    "\n",
    "print(f\"mu type annotation: {mu_type}\")\n",
    "print(f\"CombinableParameterType: {dms.custom_types.CombinableParameterType}\")\n",
    "\n",
    "# Check if the annotation matches the expected type exactly\n",
    "is_mu_exact_match = mu_type is dms.custom_types.CombinableParameterType\n",
    "print(f\"Exact match: {is_mu_exact_match}\")\n",
    "\n",
    "# Check if mu_type is ContinuousParameterType (which should be a subset of CombinableParameterType)\n",
    "is_mu_continuous = mu_type is dms.custom_types.ContinuousParameterType\n",
    "print(f\"mu is ContinuousParameterType: {is_mu_continuous}\")\n",
    "\n",
    "# For Union types, we need to check if one is a subset of the other\n",
    "# CombinableParameterType = Union[ContinuousParameterType, DiscreteParameterType]\n",
    "# So ContinuousParameterType should be a subset of CombinableParameterType\n",
    "\n",
    "# Get the args of each Union type\n",
    "mu_args = set(get_args(mu_type)) if get_origin(mu_type) else {mu_type}\n",
    "combinable_args = set(get_args(dms.custom_types.CombinableParameterType))\n",
    "\n",
    "print(f\"mu_type args: {mu_args}\")\n",
    "print(f\"CombinableParameterType args: {combinable_args}\")\n",
    "\n",
    "# Check if mu_type is a subset of CombinableParameterType\n",
    "is_subset = mu_args.issubset(combinable_args)\n",
    "print(f\"mu_type is subset of CombinableParameterType: {is_subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclease_data = load_nuclease_data(\n",
    "    \"/home/bwittmann/GitRepos/DMSStan/raw_data/nuclease/processed_data\",\n",
    "    \"/home/bwittmann/GitRepos/DMSStan/raw_data/nuclease/processed_fiducial_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1139892077.py, line 23)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef _init_fiducial_models()\u001b[39m\n                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "class NucleaseModel(Model):\n",
    "    \"\"\"Defines the DMS Stan model for the Nuclease dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: MultiNucDatasetType,\n",
    "        fluorescence_beta: float = 1.0,\n",
    "        codon_noise_sigma: float = 0.1,\n",
    "        experimental_noise_sigma: float = 0.1,\n",
    "        g1_alpha: float = 1.0,\n",
    "        g2_alpha: float = 1.0,\n",
    "        g3_alpha: float = 1.0,\n",
    "        g4_alpha: float = 1.0,\n",
    "    ):\n",
    "\n",
    "        # Store the raw data\n",
    "        self.data = data\n",
    "\n",
    "        # We have one true fluorescence value per variant. We define it on the\n",
    "        # log scale\n",
    "        self.mean_log_fluorescence = dms_components.ExpExponential(\n",
    "            beta=fluorescence_beta, shape=(len(data[\"variants\"]),)\n",
    "        )\n",
    "\n",
    "        # Define the generative model for the generation-specific fluorescence values\n",
    "        self.generation_info = self._init_gen_fluorescence(\n",
    "            codon_noise_sigma=codon_noise_sigma,\n",
    "            experimental_noise_sigma=experimental_noise_sigma,\n",
    "        )\n",
    "\n",
    "        # Define input proportions. The proportions are defined as the fraction of\n",
    "        # the total input population represented by a specific variant. Because\n",
    "        # we have many variants, we define the input proportions on the log scale\n",
    "        self._init_input_proportions(\n",
    "            g1_alpha=g1_alpha,\n",
    "            g2_alpha=g2_alpha,\n",
    "            g3_alpha=g3_alpha,\n",
    "            g4_alpha=g4_alpha,\n",
    "        )\n",
    "\n",
    "        # Calculate the proportions of the input populations that we expect to make\n",
    "        # it through a given filter. We assume that all variants experience the\n",
    "        # same noise resulting from differing codon usage. Experimental noise is\n",
    "        # already baked into the system.\n",
    "        self._calculate_output_proportions()\n",
    "\n",
    "    def _init_gen_fluorescence(\n",
    "        self, codon_noise_sigma: float, experimental_noise_sigma: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes codon-level fluorescence values for the fiducial and nonfiducial\n",
    "        variants.\n",
    "        \"\"\"\n",
    "        # We expect at least two sources of noise. One comes from different expression\n",
    "        # levels resulting from different codons and the other comes from slight\n",
    "        # differences in conditions between generations (i.e., other experimental\n",
    "        # noise).\n",
    "        self.codon_noise = dms_components.HalfNormal(sigma=codon_noise_sigma)\n",
    "        self.experimental_noise = dms_components.HalfNormal(\n",
    "            sigma=experimental_noise_sigma\n",
    "        )\n",
    "\n",
    "        # Define the fluorescence values for all generations\n",
    "        generation_info: dict[str, tuple(int, int, int)] = {}\n",
    "        for key in (\"g1\", \"g2\", \"g3\", \"g4\"):\n",
    "\n",
    "            # Get the variant indices for fiducial and non-fiducial datasets\n",
    "            fiducial_variant_inds = self.data[key][\"fiducial\"][\"variant_inds\"]\n",
    "            data_variant_inds = self.data[key][\"data\"][\"variant_inds\"]\n",
    "\n",
    "            # Ignore any data variants that are also present in the fiducial dataset.\n",
    "            # This is to avoid double counting the fluorescence values for these\n",
    "            # variants.\n",
    "            data_variant_inds = np.setdiff1d(data_variant_inds, fiducial_variant_inds)\n",
    "\n",
    "            # Get the mean fluorescence values for the population of droplets corresponding\n",
    "            # to a specific variant in this generation. This part captures the cumulative\n",
    "            # noise, which we assume to be normally distributed. To make sure we\n",
    "            # keep on the log scale, we use the ExpNormal distribution, which models\n",
    "            # a random variable whose exponential is normally distributed.\n",
    "            fiducial_mean_log_fluorescence = f\"{key}_mean_fid_log_fluorescence\"\n",
    "            data_mean_log_fluorescence = f\"{key}_mean_log_fluorescence\"\n",
    "            n_fiducial_variants = len(fiducial_variant_inds)\n",
    "            n_data_variants = len(data_variant_inds)\n",
    "            setattr(\n",
    "                self,\n",
    "                fiducial_mean_log_fluorescence,\n",
    "                dms_components.ExpNormal(\n",
    "                    mu=dms_ops.exp(self.mean_log_fluorescence[fiducial_variant_inds]),\n",
    "                    sigma=self.experimental_noise,\n",
    "                    shape=(n_fiducial_variants, 1),\n",
    "                ),\n",
    "            )\n",
    "            setattr(\n",
    "                self,\n",
    "                data_mean_log_fluorescence,\n",
    "                dms_components.ExpNormal(\n",
    "                    mu=dms_ops.exp(self.mean_log_fluorescence[data_variant_inds]),\n",
    "                    sigma=self.experimental_noise,\n",
    "                    shape=(n_data_variants,),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # Fiducial datasets have fluorescence values at the codon level. We\n",
    "            # need to expand their mean fluorescence values to the codon level.\n",
    "            # We would expect the fluorescence values here to be normally distributed\n",
    "            # on the log scale (i.e., we expect a fold change in fluorescence for\n",
    "            # different codons)\n",
    "            n_fiducial_codons = self.data[key][\"fiducial\"][\"ic1\"].shape[-1]\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"{key}_fid_codon_log_fluorescence\",\n",
    "                dms_components.Normal(\n",
    "                    mu=getattr(self, fiducial_mean_log_fluorescence),\n",
    "                    sigma=self.codon_noise,\n",
    "                    shape=(n_fiducial_variants, n_fiducial_codons),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # Record information on this generation, including the number of non-fiducial\n",
    "            # variants, the number of fiducial codon variants, and the total number\n",
    "            # of variants (non-fiducial + fiducial codons variants) for which we\n",
    "            # have count data.\n",
    "            generation_info[key] = (\n",
    "                n_data_variants,\n",
    "                n_fiducial_codons,\n",
    "                n_fiducial_variants + n_fiducial_codons,\n",
    "            )\n",
    "\n",
    "        # Return the generation information\n",
    "        return generation_info\n",
    "\n",
    "    def _init_input_proportions(\n",
    "        self, g1_alpha: float, g2_alpha: float, g3_alpha: float, g4_alpha: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the input proportions for each generation. The input proportions\n",
    "        are defined as the fraction of the total input population represented by\n",
    "        a specific variant.\n",
    "        \"\"\"\n",
    "        # TODO: Consider a hyperprior for alpha in the cases where we have multiple\n",
    "        # samples from the same Dirichlet distribution.\n",
    "        self.g1_input_log_prop = dms_components.ExpDirichlet(\n",
    "            alpha=g1_alpha,\n",
    "            shape=(\n",
    "                3,  # TODO: We are sure that there are three different samples here?\n",
    "                self.generation_info[\"g1\"][-1],\n",
    "            ),\n",
    "        )\n",
    "        self.g2_input_log_prop = dms_components.ExpDirichlet(\n",
    "            alpha=g2_alpha,\n",
    "            shape=(\n",
    "                2,  # TODO: We are sure that there are two different samples here?\n",
    "                self.generation_info[\"g2\"][-1],\n",
    "            ),\n",
    "        )\n",
    "        self.g3_input_log_prop = dms_components.ExpDirichlet(\n",
    "            alpha=g3_alpha,\n",
    "            shape=self.generation_info[\"g3\"][-1],\n",
    "        )\n",
    "        self.g4_input_log_prop = dms_components.ExpDirichlet(\n",
    "            alpha=g4_alpha,\n",
    "            shape=self.generation_info[\"g4\"][-1],\n",
    "        )\n",
    "\n",
    "    def _calculate_output_proportions(self):\n",
    "        \"\"\"\n",
    "        Calculates the expected output proportions for a population of variants\n",
    "        whose mean log fluorescence values are defined by `self.{generation}_mean_log_fluorescence`.\n",
    "        We assume that all variants experience the same noise resulting from differing\n",
    "        codon usage, so we apply the codon noise inferred from the fiducial sequences\n",
    "        to the non-fiducial sequences. We assume that all other system noise is\n",
    "        captured when we define the generational mean fluorescence values from\n",
    "        the overall mean fluorescence values. In other words, the proportion of\n",
    "        variants that make it through a given filter is the proportion of variants\n",
    "        above a certain threshold defined by the distribution of fluorescence\n",
    "        values (i.e., the complementary CDF of the fluorescence values).\n",
    "        \"\"\"\n",
    "\n",
    "        def single_calculation(\n",
    "            input_log_prop: dms_components.ExpDirichlet,\n",
    "            mean_log_fluorescence: dms_components.ExpNormal,\n",
    "            threshold: npt.NDArray[np.floating],\n",
    "        ) -> dms_components.TransformedParameter:\n",
    "            \"\"\"\n",
    "            Returns the proportion of variants that are above a given threshold.\n",
    "            Because our mean fluorescence is defined on the log scale, we need to\n",
    "            use the CDF of the log-normal distribution to calculate the proportion\n",
    "            of variants whose fluorescence values are above a given threshold.\n",
    "            \"\"\"\n",
    "            # Get the log complementary CDF of the fluorescence values\n",
    "            # TODO: Overload this function. It should be callable as an instance\n",
    "            # or a class method.\n",
    "            log_ccdf = dms_components.LogNormal(\n",
    "                mu=mean_log_fluorescence, sigma=self.codon_noise\n",
    "            ).log_ccdf(threshold)\n",
    "\n",
    "            # Now update the input log proportions to reflect the decrease.\n",
    "            raw_output_log_prop = input_log_prop + log_ccdf\n",
    "\n",
    "            # Finally, renormalize the output log proportions such that they sum\n",
    "            # to 1.0 across all variants. This is our output proportion.\n",
    "            return dms_ops.normalize_log(raw_output_log_prop)\n",
    "\n",
    "        # Calculate the output proportions, making sure to use the correct combinations\n",
    "        # of input log proportions and fluorescence thresholds for each generation.\n",
    "        for key in (\"g1\", \"g2\", \"g3\", \"g4\"):\n",
    "\n",
    "            # Calculate the output log proportions for this generation\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"{key}_output_log_prop\",\n",
    "                single_calculation(\n",
    "                    input_log_prop=getattr(self, f\"{key}_input_log_prop\"),\n",
    "                    mean_log_fluorescence=getattr(self, f\"{key}_mean_log_fluorescence\"),\n",
    "                    threshold=self.data[key][\"ft\"],\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def _model_counts(self):\n",
    "        \"\"\"\n",
    "        Defines the distributions that model our observations. These are all multinomial\n",
    "        distributions parametrized by the log proportions of the variants.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuclease_data[\"g1\"][\"fiducial\"][\"variant_inds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dms_stan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
