{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior predictive check for the TrpB datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdefaults\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdms\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdms_components\u001b[39;00m\n",
      "File \u001b[0;32m~/GitRepos/DMSStan/dms_stan/__init__.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m manual_seed()  \u001b[38;5;66;03m# Set the seed for the global random number generator\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Import the DMS Stan modules, pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaults, exceptions, plotting\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdms_stan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_types, operations\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/typeguard/_importhook.py:98\u001b[0m, in \u001b[0;36mTypeguardLoader.exec_module\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexec_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: ModuleType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Use a custom optimization marker â€“ the import lock should make this monkey\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# patch safe\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportlib._bootstrap_external.cache_from_source\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m         optimized_cache_from_source,\n\u001b[1;32m     97\u001b[0m     ):\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "File \u001b[0;32m~/GitRepos/DMSStan/dms_stan/plotting.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional, overload, ParamSpec, TypeVar, Union\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhv\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhvplot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractive\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhvplot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/hvplot/__init__.py:72\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_hv\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Store, render  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HoloViewsConverter\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interactive\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explorer  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/hvplot/converter.py:45\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m max_range\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     Curve,\n\u001b[1;32m     20\u001b[0m     Scatter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     Segments,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbokeh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OverlayPlot, colormap_generator\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_cmap\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mholoviews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m histogram, apply_when\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/holoviews/plotting/bokeh/__init__.py:106\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElementPlot, OverlayPlot\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RectanglesPlot, SegmentPlot\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChordPlot, GraphPlot, NodePlot, TriMeshPlot\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheatmap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HeatMapPlot, RadialHeatMapPlot\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhex_tiles\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HexTilesPlot\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/holoviews/plotting/bokeh/graphs.py:481\u001b[0m\n\u001b[1;32m    476\u001b[0m         mapping[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangle\u001b[39m\u001b[38;5;124m'\u001b[39m, text_baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiddle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data, mapping, style\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNodePlot\u001b[39;00m(PointPlot):\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    Simple subclass of PointPlot which hides x, y position on hover.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hover_opts\u001b[39m(\u001b[38;5;28mself\u001b[39m, element):\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/param/parameterized.py:3369\u001b[0m, in \u001b[0;36mParameterizedMetaclass.__init__\u001b[0;34m(mcs, name, bases, dict_)\u001b[0m\n\u001b[1;32m   3366\u001b[0m mcs\u001b[38;5;241m.\u001b[39mparam\u001b[38;5;241m.\u001b[39m_depends \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatch\u001b[39m\u001b[38;5;124m'\u001b[39m: _inherited\u001b[38;5;241m+\u001b[39m_watch}\n\u001b[1;32m   3368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docstring_signature:\n\u001b[0;32m-> 3369\u001b[0m     mcs\u001b[38;5;241m.\u001b[39m__class_docstring()\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/param/parameterized.py:3409\u001b[0m, in \u001b[0;36mParameterizedMetaclass.__class_docstring\u001b[0;34m(mcs)\u001b[0m\n\u001b[1;32m   3407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m class_docstr \u001b[38;5;241m=\u001b[39m mcs\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mcs\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 3409\u001b[0m description \u001b[38;5;241m=\u001b[39m param_pager(mcs)\n\u001b[1;32m   3410\u001b[0m mcs\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m class_docstr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m description\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/param/ipython.py:286\u001b[0m, in \u001b[0;36mParamPager.__call__\u001b[0;34m(self, param_obj)\u001b[0m\n\u001b[1;32m    283\u001b[0m     top_heading \u001b[38;5;241m=\u001b[39m green \u001b[38;5;241m%\u001b[39m heading_text\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_heading\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mObject has no parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 286\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_table(param_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder, max_col_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[1;32m    287\u001b[0m                           only_changed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    289\u001b[0m docstrings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_docstrings(param_info, max_col_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, only_changed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m dflt_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters changed from their default values are marked in red.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/dms_stan/lib/python3.12/site-packages/param/ipython.py:193\u001b[0m, in \u001b[0;36mParamPager._build_table\u001b[0;34m(self, info, order, max_col_len, only_changed)\u001b[0m\n\u001b[1;32m    190\u001b[0m         p_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlbound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mubound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m p_dict:\n\u001b[0;32m--> 193\u001b[0m     max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([col_widths[col], \u001b[38;5;28mlen\u001b[39m(p_dict[col])])\n\u001b[1;32m    194\u001b[0m     col_widths[col] \u001b[38;5;241m=\u001b[39m max_width\n\u001b[1;32m    196\u001b[0m info_list\u001b[38;5;241m.\u001b[39mappend((name, p_dict))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "\n",
    "import dms_stan.defaults as defaults\n",
    "import dms_stan.model as dms\n",
    "import dms_stan.model.components as dms_components\n",
    "import dms_stan.operations as dms_ops\n",
    "\n",
    "from dms_stan.model.components.abstract_model_component import AbstractModelComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trpb_dataset(filepath: str) -> dict[str, npt.NDArray]:\n",
    "    \"\"\"\n",
    "    Load a TrpB dataset from Johnston et al.\n",
    "    \"\"\"\n",
    "    # Load in the data\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    # Get the output columns\n",
    "    output_cols = sorted(\n",
    "        (col for col in data.columns if col.startswith(\"OutputCount\")),\n",
    "        key=lambda x: int(x.split(\"_\")[1]),\n",
    "    )\n",
    "\n",
    "    # Get unique combo to input counts\n",
    "    t0_data = data[[\"AAs\", \"InputCount_1\"]].drop_duplicates()\n",
    "    assert (t0_data.AAs.value_counts() == 1).all()\n",
    "    combo_order = t0_data.AAs.tolist()\n",
    "    t0_counts = t0_data.InputCount_1.to_numpy(dtype=int)\n",
    "\n",
    "    # Get the timepoint counts\n",
    "    times = data[\"Time (h)\"].unique().astype(float)\n",
    "    times.sort()\n",
    "    tg0_counts = np.zeros([len(output_cols), len(times), len(combo_order)], dtype=int)\n",
    "    for timeind, time in enumerate(times):\n",
    "\n",
    "        # Filter down to just the data for this time\n",
    "        time_data = data[data[\"Time (h)\"] == time]\n",
    "\n",
    "        # Make sure the data is in the right order\n",
    "        assert time_data.AAs.tolist() == combo_order\n",
    "\n",
    "        # Get the counts\n",
    "        tg0_counts[:, timeind, :] = time_data[output_cols].to_numpy(dtype=int).T\n",
    "\n",
    "    return {\n",
    "        \"times\": np.concatenate([[0], times]),\n",
    "        \"starting_counts\": t0_counts,\n",
    "        \"timepoint_counts\": tg0_counts,\n",
    "    }\n",
    "\n",
    "\n",
    "class TrpBGrowthModel(dms.Model):\n",
    "    \"\"\"\n",
    "    Models the TrpB count data from Johnston et al. using an exponential growth\n",
    "    function to model the time-dependent increase in counts and a multinomial distribution\n",
    "    to model the counts at each timepoint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        times: npt.NDArray[np.floating],\n",
    "        starting_counts: npt.NDArray[np.integer],\n",
    "        timepoint_counts: npt.NDArray[np.integer],\n",
    "    ):\n",
    "\n",
    "        # Check shapes. Times and starting counts should be 1D arrays. Timepoint\n",
    "        # counts should be a 3D array with shape (n_replicates, n_timepoints - 1, n_variants)\n",
    "        if times.ndim != 1:\n",
    "            raise ValueError(\"Times should be a 1D array\")\n",
    "        if starting_counts.ndim != 1:\n",
    "            raise ValueError(\"Starting counts should be a 1D array\")\n",
    "        if timepoint_counts.ndim != 3:\n",
    "            raise ValueError(\"Timepoint counts should be a 3D array\")\n",
    "\n",
    "        # Get the number of timepoints, replicates, and variants\n",
    "        n_timepoints = len(times)\n",
    "        n_replicates = timepoint_counts.shape[0]\n",
    "        n_variants = timepoint_counts.shape[2]\n",
    "\n",
    "        # Check that the shapes of the arrays are consistent\n",
    "        if n_timepoints != timepoint_counts.shape[1] + 1:\n",
    "            raise ValueError(\n",
    "                \"Timepoint counts should have one fewer timepoint than the number \"\n",
    "                \"of times\"\n",
    "            )\n",
    "        if starting_counts.shape[0] != n_variants:\n",
    "            raise ValueError(\n",
    "                \"Starting counts and timepoint counts should have the same number \"\n",
    "                \"of replicates\"\n",
    "            )\n",
    "\n",
    "        # Normalize the times such that the maximum timepoint is 1\n",
    "        times = times / times.max()\n",
    "        if times[0] != 0.0:\n",
    "            raise ValueError(\"Times should start at 0\")\n",
    "\n",
    "        # Now start building the generative model.\n",
    "        # Hyperparameters first\n",
    "        self.log_A = dms_components.Normal(mu=0.0, sigma=0.05, shape=(n_variants,))\n",
    "\n",
    "        self.r_mean = dms_components.Exponential(beta=0.5, shape=(n_variants,))\n",
    "        self.r_std = dms_components.HalfNormal(sigma=0.1)  # Shared across variants\n",
    "\n",
    "        # Now the next layer of the model. Both technical replicates start from\n",
    "        # the same culture, so the starting counts (and hence log_A) are the same.\n",
    "        # The growth rate might vary between replicates, however, so we model a\n",
    "        # separate one for each replicate.\n",
    "        self.r = dms_components.Normal(\n",
    "            mu=self.r_mean, sigma=self.r_std, shape=(n_replicates, 1, n_variants)\n",
    "        )\n",
    "\n",
    "        # Calculate the thetas at t = 0. This is just the log_A values normalized\n",
    "        self.theta_t0 = dms_ops.exp(dms_ops.normalize_log(self.log_A))\n",
    "\n",
    "        # Calculate the thetas a t > 0. This is the result of log exponential growth\n",
    "        self.theta_tg0 = dms_ops.exp(\n",
    "            dms_ops.normalize_log(\n",
    "                dms_components.LogExponentialGrowth(\n",
    "                    log_A=self.log_A,\n",
    "                    r=self.r,\n",
    "                    t=dms_components.Constant(times[None, 1:, None], togglable=False),\n",
    "                    shape=(n_replicates, n_timepoints - 1, n_variants),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Model the counts data.\n",
    "        self.starting_counts = dms_components.Multinomial(\n",
    "            theta=self.theta_t0,\n",
    "            N=dms_components.Constant(starting_counts.sum(), togglable=False),\n",
    "            shape=(n_variants,),\n",
    "        ).as_observable()\n",
    "        self.timepoint_counts = dms_components.Multinomial(\n",
    "            theta=self.theta_tg0,\n",
    "            N=dms_components.Constant(\n",
    "                timepoint_counts.sum(axis=-1, keepdims=True), togglable=False\n",
    "            ),\n",
    "            shape=timepoint_counts.shape,\n",
    "        ).as_observable()\n",
    "\n",
    "        # Record the data\n",
    "        self.times = times\n",
    "        self.starting_counts_data = starting_counts\n",
    "        self.timepoint_counts_data = timepoint_counts\n",
    "\n",
    "    def approximate_map(self, *args, **kwargs):\n",
    "        \"\"\"Approximates the MAP estimate of the model.\"\"\"\n",
    "        return super().approximate_map(\n",
    "            *args,\n",
    "            **kwargs,\n",
    "            starting_counts=self.starting_counts_data,\n",
    "            timepoint_counts=self.timepoint_counts_data\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_file(cls, filepath: str):\n",
    "        \"\"\"\n",
    "        Load a TrpB dataset from Johnston et al. and create a model from it.\n",
    "        \"\"\"\n",
    "        return cls(**load_trpb_dataset(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNNG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596b646463814550b1f9413525372dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'94547d96-f657-4d29-98a8-5086b5ad5fdc': {'versionâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_trpb_dataset(\n",
    "    \"~/GitRepos/DMSStan/raw_data/trpb/3-site_merged_replicates/LibI/20230926/LibI_merged_AAs.csv\"\n",
    ")\n",
    "model = TrpBGrowthModel(**data)\n",
    "model.prior_predictive(\n",
    "    independent_dim = 1,\n",
    "    independent_labels = data[\"times\"][1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp = dms.prior_predictive.PriorPredictiveCheck(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
