<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Neural Network Module API Reference &#8212; SciStanPy Alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=27fed22d" />
    <script src="../../_static/documentation_options.js?v=6b921976"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Model Results API Reference" href="results/index.html" />
    <link rel="prev" title="Model API Reference" href="model.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-scistanpy.model.nn_module">
<span id="neural-network-module-api-reference"></span><h1>Neural Network Module API Reference<a class="headerlink" href="#module-scistanpy.model.nn_module" title="Link to this heading">¶</a></h1>
<p>PyTorch integration utilities for SciStanPy models.</p>
<p>This module provides integration between SciStanPy probabilistic models
and PyTorch’s automatic differentiation and optimization framework. It enables
maximum likelihood estimation, variational inference, and other gradient-based
learning procedures on SciStanPy models.</p>
<p>The module’s core functionality centers around converting SciStanPy models into
PyTorch <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instances that preserve the probabilistic structure while
enabling efficient gradient computation and optimization. This allows users to
leverage PyTorch’s ecosystem of optimizers, learning rate schedulers, and other
training utilities.</p>
<dl class="simple">
<dt>Key Features:</dt><dd><ul class="simple">
<li><p>Automatic conversion of SciStanPy models to PyTorch modules</p></li>
<li><p>Gradient-based parameter optimization with various optimizers</p></li>
<li><p>Mixed precision training support for improved performance</p></li>
<li><p>Early stopping and convergence monitoring</p></li>
<li><p>GPU acceleration and device management</p></li>
</ul>
</dd>
</dl>
<section id="core-pytorch-integration">
<h2>Core PyTorch Integration<a class="headerlink" href="#core-pytorch-integration" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">scistanpy.model.nn_module.</span></span><span class="sig-name descname"><span class="pre">PyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>PyTorch-trainable version of a SciStanPy Model.</p>
<p>This class converts SciStanPy probabilistic models into PyTorch nn.Module
instances that can be optimized using standard PyTorch training procedures.
It preserves the probabilistic structure while enabling gradient-based
parameter estimation and other machine learning techniques.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>ssp_model.Model</em>) – SciStanPy model to convert to PyTorch</p></li>
<li><p><strong>seed</strong> (<em>Optional</em><em>[</em><em>custom_types.Integer</em><em>]</em>) – Random seed for reproducible parameter initialization. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Variables<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> – Reference to the original SciStanPy model</p></li>
<li><p><strong>learnable_params</strong> – PyTorch ParameterList containing optimizable parameters</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>The conversion process:</dt><dd><ul class="simple">
<li><p>Initializes all model parameters for PyTorch optimization</p></li>
<li><p>Sets up proper gradient computation graphs</p></li>
<li><p>Configures device placement and memory management</p></li>
<li><p>Preserves probabilistic model structure and relationships</p></li>
</ul>
</dd>
</dl>
<p>The resulting PyTorch model can be treated like any other nn.Module.</p>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_pytorch</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">pytorch_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">pytorch_model</span><span class="p">(</span><span class="o">**</span><span class="n">observed_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This class should not be instantiated directly. Instead, use the
<cite>to_pytorch()</cite> method on a SciStanPy Model instance.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.cpu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.cpu" title="Link to this definition">¶</a></dt>
<dd><p>Move model to CPU device.</p>
<p>This method transfers the entire model (including SciStanPy constants)
to CPU memory, which is useful for inference or when GPU memory is limited.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – Arguments passed to torch.nn.Module.cpu()</p></li>
<li><p><strong>kwargs</strong> – Keyword arguments passed to torch.nn.Module.cpu()</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Self reference for method chaining</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel" title="scistanpy.model.nn_module.PyTorchModel">PyTorchModel</a></p>
</dd>
</dl>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  <span class="c1"># Move to CPU</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.cuda"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.cuda" title="Link to this definition">¶</a></dt>
<dd><p>Move model to CUDA device.</p>
<p>This method transfers the entire model (including SciStanPy constants)
to a CUDA-enabled GPU device for accelerated computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – Arguments passed to torch.nn.Module.cuda()</p></li>
<li><p><strong>kwargs</strong> – Keyword arguments passed to torch.nn.Module.cuda()</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Self reference for method chaining</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel" title="scistanpy.model.nn_module.PyTorchModel">PyTorchModel</a></p>
</dd>
</dl>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>  <span class="c1"># Move to default GPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Move to GPU 1</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.export_distributions">
<span class="sig-name descname"><span class="pre">export_distributions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.distributions.Distribution</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.export_distributions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.export_distributions" title="Link to this definition">¶</a></dt>
<dd><p>Export fitted probability distributions for all model components.</p>
<p>This method returns the complete set of probability distributions
from the fitted model, including both parameter distributions (priors)
and observable distributions (likelihoods) with their current
parameter values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary mapping component names to their distribution objects</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, torch.distributions.Distribution]</p>
</dd>
</dl>
<dl>
<dt>The exported distributions include:</dt><dd><ul class="simple">
<li><p>Parameter distributions with updated hyperparameter values</p></li>
<li><p>Observable distributions with fitted parameter values</p></li>
<li><p>All distributions in their PyTorch format for further computation</p></li>
</ul>
</dd>
<dt>This is useful for:</dt><dd><ul class="simple">
<li><p>Posterior predictive sampling</p></li>
<li><p>Model diagnostics and validation</p></li>
<li><p>Uncertainty quantification</p></li>
<li><p>Distribution comparison and analysis</p></li>
</ul>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">distributions</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">export_distributions</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fitted_normal</span> <span class="o">=</span> <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span>  <span class="c1"># torch.distributions.Normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">fitted_normal</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1000</span><span class="p">,))</span>  <span class="c1"># Sample from fit distribution</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.export_params">
<span class="sig-name descname"><span class="pre">export_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.export_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.export_params" title="Link to this definition">¶</a></dt>
<dd><p>Export optimized parameter values from the fitted model.</p>
<p>This method extracts the current parameter values after optimization,
providing access to the maximum likelihood estimates or other fitted
parameter values. It excludes observable parameters (which represent
data) and focuses on the learnable model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary mapping parameter names to their current tensor values</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, torch.Tensor]</p>
</dd>
</dl>
<dl class="simple">
<dt>Excluded from export:</dt><dd><ul class="simple">
<li><p>Observable parameters (representing data, not learnable parameters)</p></li>
<li><p>Unnamed parameters</p></li>
<li><p>Intermediate computational results from transformations</p></li>
</ul>
</dd>
</dl>
<p>This is typically used after model fitting to extract the estimated
parameter values for further analysis or model comparison.</p>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fitted_params</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">export_params</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mu_estimate</span> <span class="o">=</span> <span class="n">fitted_params</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sigma_estimate</span> <span class="o">=</span> <span class="n">fitted_params</span><span class="p">[</span><span class="s1">&#39;sigma&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">custom_types.Integer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100000</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">early_stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">custom_types.Integer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">custom_types.Float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dtype</span><span class="p"><span class="pre">[</span></span><span class="pre">_ScalarType_co</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">custom_types.Float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">custom_types.Integer</span><span class="p"><span class="pre">]</span></span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">mixed_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>,</dd>
</dl>

<span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.fit" title="Link to this definition">¶</a></dt>
<dd><p>Optimize model parameters using gradient-based maximum likelihood estimation.</p>
<p>This method performs complete model training using the Adam optimizer
with configurable early stopping, learning rate, and mixed precision
support. It automatically handles device placement, gradient computation,
and convergence monitoring.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epochs</strong> (<em>custom_types.Integer</em>) – Maximum number of training epochs. Defaults to 100000.</p></li>
<li><p><strong>early_stop</strong> (<em>custom_types.Integer</em>) – Epochs without improvement before stopping. Defaults to 10.</p></li>
<li><p><strong>lr</strong> (<em>custom_types.Float</em>) – Learning rate for Adam optimizer. Defaults to 0.001.</p></li>
<li><p><strong>data</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>npt.NDArray</em><em>, </em><em>custom_types.Float</em><em>,
</em><em>custom_types.Integer</em><em>]</em><em>]</em>) – Observed data for model observables</p></li>
<li><p><strong>mixed_precision</strong> (<em>bool</em>) – Whether to use automatic mixed precision. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor containing loss trajectory throughout training</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>UserWarning</strong> – If early stopping is not triggered within epoch limit</p>
</dd>
</dl>
<dl>
<dt>The training loop:</dt><dd><ol class="arabic simple">
<li><p>Converts input data to appropriate tensor format</p></li>
<li><p>Validates data compatibility with model observables</p></li>
<li><p>Iteratively optimizes parameters using gradient descent</p></li>
<li><p>Monitors convergence and applies early stopping</p></li>
<li><p>Returns complete loss trajectory for analysis</p></li>
</ol>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_history</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">observed_data</span><span class="p">},</span>
<span class="gp">... </span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">early_stop</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">mixed_precision</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_loss</span> <span class="o">=</span> <span class="n">loss_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.forward" title="Link to this definition">¶</a></dt>
<dd><p>Compute log probability of observed data given current parameters.</p>
<p>This method calculates the total log probability (log-likelihood) of
the observed data under the current model parameters. It forms the
core objective function for maximum likelihood estimation and other
gradient-based inference procedures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Observed data tensors keyed by observable parameter names</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Total log probability of the observed data</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>This returns log probability, <em>not</em> log loss (negative log probability).
For optimization, negate the result to get the loss function.</p>
</div>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">log_prob</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">observed_y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">observed_x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span>  <span class="c1"># Negative for minimization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scistanpy.model.nn_module.PyTorchModel.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/scistanpy/model/nn_module.html#PyTorchModel.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#scistanpy.model.nn_module.PyTorchModel.to" title="Link to this definition">¶</a></dt>
<dd><p>Move model to specified device or data type.</p>
<p>This method provides flexible device and dtype conversion for the
entire model, including both PyTorch parameters and SciStanPy
constant tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – Arguments passed to torch.nn.Module.to()</p></li>
<li><p><strong>kwargs</strong> – Keyword arguments passed to torch.nn.Module.to()</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Self reference for method chaining</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel" title="scistanpy.model.nn_module.PyTorchModel">PyTorchModel</a></p>
</dd>
</dl>
<dl>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>  <span class="c1"># Move to specific GPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c1"># Change precision</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">SciStanPy</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">SciStanPy API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../custom_types.html">Custom Types API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../defaults.html">Defaults API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exceptions.html">Exceptions API Reference</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Model SubPackage API Reference</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="index.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="components/index.html">Model Components API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="model.html">Model API Reference</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Neural Network Module API Reference</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#core-pytorch-integration">Core PyTorch Integration</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel"><code class="docutils literal notranslate"><span class="pre">PyTorchModel</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.cpu"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.cpu()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.cuda"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.cuda()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.export_distributions"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.export_distributions()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.export_params"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.export_params()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.fit"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.fit()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.forward"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.forward()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#scistanpy.model.nn_module.PyTorchModel.to"><code class="docutils literal notranslate"><span class="pre">PyTorchModel.to()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="results/index.html">Model Results API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="stan/index.html">Stan Submodule API Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../plotting/index.html">Plotting Subpackage API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../operations.html">Operations API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils.html">Utils API Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Examples</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">SciStanPy API Reference</a><ul>
  <li><a href="index.html">Model SubPackage API Reference</a><ul>
      <li>Previous: <a href="model.html" title="previous chapter">Model API Reference</a></li>
      <li>Next: <a href="results/index.html" title="next chapter">Model Results API Reference</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Microsoft Corporation.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.3.0</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../../_sources/api/model/nn_module.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>